{"nbformat":4,"nbformat_minor":5,"metadata":{"colab":{"name":"KM_challenge_new.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fourth-republic"},"source":["# Kernel Methods: Challenge"],"id":"fourth-republic"},{"cell_type":"markdown","metadata":{"id":"surrounded-shift"},"source":["Julia Linhart, Roman Castagné, Louis Bouvier"],"id":"surrounded-shift"},{"cell_type":"code","metadata":{"id":"sensitive-associate","executionInfo":{"status":"ok","timestamp":1616594212247,"user_tz":-60,"elapsed":7718,"user":{"displayName":"Julia Linhart","photoUrl":"","userId":"01343193259563128268"}}},"source":["%load_ext autoreload\n","%autoreload 2\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from functools import partial\n","from scipy.spatial import distance_matrix\n","from sklearn.base import BaseEstimator, ClassifierMixin\n","from sklearn.model_selection import GridSearchCV\n","import cvxpy as cp\n","import warnings\n","import time\n","from itertools import product\n","from numba import jit\n","\n","from utils import run_model, write_csv\n","\n","\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"],"id":"sensitive-associate","execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"remarkable-description"},"source":["# I) Preprocessing"],"id":"remarkable-description"},{"cell_type":"code","metadata":{"id":"developing-reference"},"source":["data_folder = 'data' # 'machine-learning-with-kernel-methods-2021'\n","\n","X_train_1 = pd.read_csv(f'{data_folder}/Xtr2_mat100.csv', sep = ' ', index_col=False, header=None)\n","y_train_1 = pd.read_csv(f'{data_folder}/Ytr2.csv')"],"id":"developing-reference","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":277},"id":"swedish-thriller","executionInfo":{"elapsed":1416,"status":"ok","timestamp":1615214717474,"user":{"displayName":"Julia Linhart","photoUrl":"","userId":"01343193259563128268"},"user_tz":-60},"outputId":"0ec06def-2c33-45fe-c193-dd58c3856c53"},"source":["y_train_1.describe()"],"id":"swedish-thriller","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Bound</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>4999.500000</td>\n","      <td>0.498500</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>577.494589</td>\n","      <td>0.500123</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>4000.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>4499.750000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>4999.500000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>5499.250000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>5999.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                Id        Bound\n","count  2000.000000  2000.000000\n","mean   4999.500000     0.498500\n","std     577.494589     0.500123\n","min    4000.000000     0.000000\n","25%    4499.750000     0.000000\n","50%    4999.500000     0.000000\n","75%    5499.250000     1.000000\n","max    5999.000000     1.000000"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"burning-functionality"},"source":["y_train_1 = np.array(y_train_1)[:,1]"],"id":"burning-functionality","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":325},"id":"variable-bearing","executionInfo":{"elapsed":1704,"status":"ok","timestamp":1615214718208,"user":{"displayName":"Julia Linhart","photoUrl":"","userId":"01343193259563128268"},"user_tz":-60},"outputId":"d1954cab-929d-45ad-9036-ce37da327a36"},"source":["X_train_1.describe()"],"id":"variable-bearing","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>...</th>\n","      <th>60</th>\n","      <th>61</th>\n","      <th>62</th>\n","      <th>63</th>\n","      <th>64</th>\n","      <th>65</th>\n","      <th>66</th>\n","      <th>67</th>\n","      <th>68</th>\n","      <th>69</th>\n","      <th>70</th>\n","      <th>71</th>\n","      <th>72</th>\n","      <th>73</th>\n","      <th>74</th>\n","      <th>75</th>\n","      <th>76</th>\n","      <th>77</th>\n","      <th>78</th>\n","      <th>79</th>\n","      <th>80</th>\n","      <th>81</th>\n","      <th>82</th>\n","      <th>83</th>\n","      <th>84</th>\n","      <th>85</th>\n","      <th>86</th>\n","      <th>87</th>\n","      <th>88</th>\n","      <th>89</th>\n","      <th>90</th>\n","      <th>91</th>\n","      <th>92</th>\n","      <th>93</th>\n","      <th>94</th>\n","      <th>95</th>\n","      <th>96</th>\n","      <th>97</th>\n","      <th>98</th>\n","      <th>99</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>...</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","      <td>2000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.010565</td>\n","      <td>0.010201</td>\n","      <td>0.010375</td>\n","      <td>0.011587</td>\n","      <td>0.011609</td>\n","      <td>0.010707</td>\n","      <td>0.009359</td>\n","      <td>0.011957</td>\n","      <td>0.009571</td>\n","      <td>0.010582</td>\n","      <td>0.009424</td>\n","      <td>0.009793</td>\n","      <td>0.012848</td>\n","      <td>0.012092</td>\n","      <td>0.011196</td>\n","      <td>0.010364</td>\n","      <td>0.009875</td>\n","      <td>0.010962</td>\n","      <td>0.010185</td>\n","      <td>0.008342</td>\n","      <td>0.010734</td>\n","      <td>0.010038</td>\n","      <td>0.011554</td>\n","      <td>0.008995</td>\n","      <td>0.010283</td>\n","      <td>0.008647</td>\n","      <td>0.008886</td>\n","      <td>0.008826</td>\n","      <td>0.007821</td>\n","      <td>0.009761</td>\n","      <td>0.008533</td>\n","      <td>0.011864</td>\n","      <td>0.009299</td>\n","      <td>0.010641</td>\n","      <td>0.009560</td>\n","      <td>0.008929</td>\n","      <td>0.010217</td>\n","      <td>0.009641</td>\n","      <td>0.009880</td>\n","      <td>0.010038</td>\n","      <td>...</td>\n","      <td>0.009511</td>\n","      <td>0.010614</td>\n","      <td>0.011957</td>\n","      <td>0.009641</td>\n","      <td>0.011772</td>\n","      <td>0.009500</td>\n","      <td>0.008783</td>\n","      <td>0.010005</td>\n","      <td>0.010870</td>\n","      <td>0.009147</td>\n","      <td>0.013565</td>\n","      <td>0.010587</td>\n","      <td>0.009793</td>\n","      <td>0.010908</td>\n","      <td>0.009500</td>\n","      <td>0.009772</td>\n","      <td>0.009103</td>\n","      <td>0.010147</td>\n","      <td>0.008587</td>\n","      <td>0.010538</td>\n","      <td>0.010897</td>\n","      <td>0.008913</td>\n","      <td>0.008630</td>\n","      <td>0.008380</td>\n","      <td>0.009016</td>\n","      <td>0.011478</td>\n","      <td>0.008832</td>\n","      <td>0.009989</td>\n","      <td>0.010587</td>\n","      <td>0.008625</td>\n","      <td>0.007951</td>\n","      <td>0.009457</td>\n","      <td>0.008554</td>\n","      <td>0.009283</td>\n","      <td>0.008261</td>\n","      <td>0.009614</td>\n","      <td>0.011141</td>\n","      <td>0.009777</td>\n","      <td>0.008217</td>\n","      <td>0.008565</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.012278</td>\n","      <td>0.010723</td>\n","      <td>0.011467</td>\n","      <td>0.011453</td>\n","      <td>0.012182</td>\n","      <td>0.010478</td>\n","      <td>0.009789</td>\n","      <td>0.012444</td>\n","      <td>0.013805</td>\n","      <td>0.013652</td>\n","      <td>0.012934</td>\n","      <td>0.011163</td>\n","      <td>0.027178</td>\n","      <td>0.018160</td>\n","      <td>0.011200</td>\n","      <td>0.010356</td>\n","      <td>0.010089</td>\n","      <td>0.019951</td>\n","      <td>0.010631</td>\n","      <td>0.009920</td>\n","      <td>0.011238</td>\n","      <td>0.010962</td>\n","      <td>0.011475</td>\n","      <td>0.009723</td>\n","      <td>0.010922</td>\n","      <td>0.009933</td>\n","      <td>0.009622</td>\n","      <td>0.009861</td>\n","      <td>0.010099</td>\n","      <td>0.010628</td>\n","      <td>0.009945</td>\n","      <td>0.010829</td>\n","      <td>0.010358</td>\n","      <td>0.010460</td>\n","      <td>0.011039</td>\n","      <td>0.009612</td>\n","      <td>0.010705</td>\n","      <td>0.012258</td>\n","      <td>0.020208</td>\n","      <td>0.011266</td>\n","      <td>...</td>\n","      <td>0.010436</td>\n","      <td>0.011172</td>\n","      <td>0.012915</td>\n","      <td>0.010912</td>\n","      <td>0.011305</td>\n","      <td>0.016977</td>\n","      <td>0.014644</td>\n","      <td>0.012108</td>\n","      <td>0.011800</td>\n","      <td>0.009647</td>\n","      <td>0.011868</td>\n","      <td>0.011752</td>\n","      <td>0.013102</td>\n","      <td>0.010237</td>\n","      <td>0.009652</td>\n","      <td>0.009687</td>\n","      <td>0.011871</td>\n","      <td>0.010457</td>\n","      <td>0.012348</td>\n","      <td>0.011010</td>\n","      <td>0.011005</td>\n","      <td>0.010695</td>\n","      <td>0.009248</td>\n","      <td>0.010494</td>\n","      <td>0.009279</td>\n","      <td>0.011204</td>\n","      <td>0.010571</td>\n","      <td>0.015973</td>\n","      <td>0.009745</td>\n","      <td>0.011904</td>\n","      <td>0.009605</td>\n","      <td>0.009701</td>\n","      <td>0.009350</td>\n","      <td>0.009741</td>\n","      <td>0.012341</td>\n","      <td>0.010338</td>\n","      <td>0.010863</td>\n","      <td>0.010402</td>\n","      <td>0.009709</td>\n","      <td>0.009283</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.000000</td>\n","      <td>0.010870</td>\n","      <td>0.000000</td>\n","      <td>0.010870</td>\n","      <td>0.000000</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.000000</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.000000</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.000000</td>\n","      <td>0.010870</td>\n","      <td>...</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.000000</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.000000</td>\n","      <td>0.010870</td>\n","      <td>0.000000</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.000000</td>\n","      <td>0.010870</td>\n","      <td>0.000000</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.000000</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.010870</td>\n","      <td>0.021739</td>\n","      <td>0.021739</td>\n","      <td>0.021739</td>\n","      <td>0.021739</td>\n","      <td>0.021739</td>\n","      <td>0.010870</td>\n","      <td>0.021739</td>\n","      <td>0.010870</td>\n","      <td>0.021739</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.021739</td>\n","      <td>0.021739</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.021739</td>\n","      <td>0.010870</td>\n","      <td>0.021739</td>\n","      <td>0.010870</td>\n","      <td>0.021739</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.021739</td>\n","      <td>0.010870</td>\n","      <td>0.021739</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.021739</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>...</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.021739</td>\n","      <td>0.010870</td>\n","      <td>0.021739</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.021739</td>\n","      <td>0.021739</td>\n","      <td>0.010870</td>\n","      <td>0.021739</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.021739</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.021739</td>\n","      <td>0.021739</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.021739</td>\n","      <td>0.010870</td>\n","      <td>0.021739</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.021739</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","      <td>0.010870</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.086957</td>\n","      <td>0.065217</td>\n","      <td>0.097826</td>\n","      <td>0.065217</td>\n","      <td>0.065217</td>\n","      <td>0.054348</td>\n","      <td>0.054348</td>\n","      <td>0.076087</td>\n","      <td>0.097826</td>\n","      <td>0.184783</td>\n","      <td>0.108696</td>\n","      <td>0.065217</td>\n","      <td>0.239130</td>\n","      <td>0.141304</td>\n","      <td>0.076087</td>\n","      <td>0.054348</td>\n","      <td>0.065217</td>\n","      <td>0.141304</td>\n","      <td>0.054348</td>\n","      <td>0.065217</td>\n","      <td>0.076087</td>\n","      <td>0.108696</td>\n","      <td>0.076087</td>\n","      <td>0.054348</td>\n","      <td>0.065217</td>\n","      <td>0.065217</td>\n","      <td>0.054348</td>\n","      <td>0.054348</td>\n","      <td>0.065217</td>\n","      <td>0.065217</td>\n","      <td>0.097826</td>\n","      <td>0.065217</td>\n","      <td>0.065217</td>\n","      <td>0.065217</td>\n","      <td>0.119565</td>\n","      <td>0.043478</td>\n","      <td>0.054348</td>\n","      <td>0.141304</td>\n","      <td>0.206522</td>\n","      <td>0.065217</td>\n","      <td>...</td>\n","      <td>0.065217</td>\n","      <td>0.086957</td>\n","      <td>0.119565</td>\n","      <td>0.065217</td>\n","      <td>0.065217</td>\n","      <td>0.119565</td>\n","      <td>0.239130</td>\n","      <td>0.076087</td>\n","      <td>0.086957</td>\n","      <td>0.065217</td>\n","      <td>0.065217</td>\n","      <td>0.076087</td>\n","      <td>0.086957</td>\n","      <td>0.065217</td>\n","      <td>0.043478</td>\n","      <td>0.054348</td>\n","      <td>0.086957</td>\n","      <td>0.054348</td>\n","      <td>0.097826</td>\n","      <td>0.065217</td>\n","      <td>0.076087</td>\n","      <td>0.065217</td>\n","      <td>0.043478</td>\n","      <td>0.065217</td>\n","      <td>0.043478</td>\n","      <td>0.065217</td>\n","      <td>0.086957</td>\n","      <td>0.108696</td>\n","      <td>0.065217</td>\n","      <td>0.097826</td>\n","      <td>0.054348</td>\n","      <td>0.065217</td>\n","      <td>0.054348</td>\n","      <td>0.054348</td>\n","      <td>0.086957</td>\n","      <td>0.065217</td>\n","      <td>0.076087</td>\n","      <td>0.065217</td>\n","      <td>0.065217</td>\n","      <td>0.043478</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 100 columns</p>\n","</div>"],"text/plain":["                0            1   ...           98           99\n","count  2000.000000  2000.000000  ...  2000.000000  2000.000000\n","mean      0.010565     0.010201  ...     0.008217     0.008565\n","std       0.012278     0.010723  ...     0.009709     0.009283\n","min       0.000000     0.000000  ...     0.000000     0.000000\n","25%       0.000000     0.000000  ...     0.000000     0.000000\n","50%       0.010870     0.010870  ...     0.010870     0.010870\n","75%       0.010870     0.021739  ...     0.010870     0.010870\n","max       0.086957     0.065217  ...     0.065217     0.043478\n","\n","[8 rows x 100 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"precious-canvas"},"source":["X_train_1 = np.array(X_train_1)\n","X_train_1 = (X_train_1 - X_train_1.mean(axis=0))/X_train_1.std(axis=0)"],"id":"precious-canvas","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"departmental-digest"},"source":["# II) First linear models of the mat100 input"],"id":"departmental-digest"},{"cell_type":"markdown","metadata":{"id":"perfect-gambling"},"source":["## A) Logistic regression"],"id":"perfect-gambling"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"micro-christopher","outputId":"92650470-a6b5-46b8-8808-ce62ef26e537"},"source":["from utils import run_model\n","\n","run_model('logreg')"],"id":"micro-christopher","execution_count":null,"outputs":[{"output_type":"stream","text":["C:\\Users\\roman\\Documents\\Academic\\2020_MVA\\S2_KernelMethods\\KM_challenge\\functions.py:103: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n","To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n","  inv_hess, _, _, _ = np.linalg.lstsq(hess, np.eye(hess.shape[0]))\n","C:\\Users\\roman\\Documents\\Academic\\2020_MVA\\S2_KernelMethods\\KM_challenge\\functions.py:111: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n","To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n","  inv_hess, _, _, _ = np.linalg.lstsq(hess, np.eye(hess.shape[0]))\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on train set 0: 0.62\n","Accuracy on test set 0 : 0.56\n","Accuracy on train set 1: 0.60\n","Accuracy on test set 1 : 0.59\n","Accuracy on train set 2: 0.70\n","Accuracy on test set 2 : 0.66\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sacred-bowling","scrolled":true},"source":["from utils import write_csv\n","\n","ids = np.arange(all_y_eval.shape[0])\n","filename = \"results/submission_log_reg.csv\"\n","\n","# write_csv(ids, all_y_eval, filename)"],"id":"sacred-bowling","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"regional-bhutan"},"source":["## B) Ridge regression"],"id":"regional-bhutan"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"steady-diversity","outputId":"a8e42c29-bb95-42cb-a4e8-093a9b6dc4c7"},"source":["run_model('rr')"],"id":"steady-diversity","execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy on train set 0: 0.65\n","Accuracy on test set 0 : 0.60\n","Accuracy on train set 1: 0.64\n","Accuracy on test set 1 : 0.57\n","Accuracy on train set 2: 0.73\n","Accuracy on test set 2 : 0.69\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"attended-poetry"},"source":["# III) Kernel baselines "],"id":"attended-poetry"},{"cell_type":"markdown","metadata":{"id":"front-music"},"source":["## A) Gaussian Kernel"],"id":"front-music"},{"cell_type":"markdown","metadata":{"id":"german-frost"},"source":["### a) Kernel Ridge Regression"],"id":"german-frost"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"neutral-proof","outputId":"125e6fc4-ae04-4a84-be5f-0a094309014f"},"source":["## run kernel ridge regression with gaussian kernel\n","run_model('krr', kernel='gaussian', prop_test=0.2, use_grid_search=True)"],"id":"neutral-proof","execution_count":null,"outputs":[{"output_type":"stream","text":["{'kernel': 'gaussian', 'lamb': 0.1, 'sigma': 0.5789473684210527}\n","Accuracy on train set 0: 1.00\n","Accuracy on test set 0 : 0.57\n","{'kernel': 'gaussian', 'lamb': 0.1, 'sigma': 0.6578947368421053}\n","Accuracy on train set 1: 1.00\n","Accuracy on test set 1 : 0.59\n","{'kernel': 'gaussian', 'lamb': 0.1, 'sigma': 0.5}\n","Accuracy on train set 2: 1.00\n","Accuracy on test set 2 : 0.67\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"central-container"},"source":["### b) Kernel SVM"],"id":"central-container"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"medical-finger","outputId":"fb2f6572-8915-430a-962f-ae6f53f40a63"},"source":["## run kernel SVM with gaussian kernel\n","run_model('ksvm', kernel='gaussian', prop_test=0.2)"],"id":"medical-finger","execution_count":null,"outputs":[{"output_type":"stream","text":["{'kernel': 'gaussian', 'lamb': 1e-07, 'sigma': 100.0}\n","Accuracy on train set 0: 0.99\n","Accuracy on test set 0 : 0.62\n","{'kernel': 'gaussian', 'lamb': 1e-10, 'sigma': 1.0}\n","Accuracy on train set 1: 1.00\n","Accuracy on test set 1 : 0.60\n","{'kernel': 'gaussian', 'lamb': 1e-07, 'sigma': 100.0}\n","Accuracy on train set 2: 0.99\n","Accuracy on test set 2 : 0.72\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"foreign-computer"},"source":["## B) Spectrum kernel"],"id":"foreign-computer"},{"cell_type":"code","metadata":{"id":"dress-guyana"},"source":["from kernels import Spectrum_kernel"],"id":"dress-guyana","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"impressive-antique","outputId":"d56aaefc-45af-4b11-f0da-6318adf4b2cd"},"source":["# Example when using a precomputed kernel\n","K = []\n","for name in [0, 1, 2]:\n","    X    = np.array(pd.read_csv(f'{data_folder}/Xtr{name}.csv')['seq'])\n","    X_ev = np.array(pd.read_csv(f'{data_folder}/Xte{name}.csv')['seq'])\n","    \n","    t0 = time.time()\n","    K_tr = Spectrum_kernel(X, X, k=6)\n","    print(f\"Time to compute train kernel : {time.time() - t0}\")\n","    K_te = Spectrum_kernel(X, X_ev, k=6)\n","    \n","    K.append({\"train\": K_tr, \"eval\": K_te})"],"id":"impressive-antique","execution_count":null,"outputs":[{"output_type":"stream","text":["Time to compute train kernel : 0.40921711921691895\n","Time to compute train kernel : 0.41764307022094727\n","Time to compute train kernel : 0.4125230312347412\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"considered-mission"},"source":["## run kernel SVM with gaussian kernel\n","run_model('ksvm', kernel='spectrum', K=K, sequence=True, prop_test=0.2)"],"id":"considered-mission","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"built-representative"},"source":["### a) Kernel SVM\n"],"id":"built-representative"},{"cell_type":"markdown","metadata":{"id":"accompanied-moldova"},"source":["## C) Substring kernel"],"id":"accompanied-moldova"},{"cell_type":"code","metadata":{"id":"metropolitan-banking"},"source":["from kernels import substring_similarity, substring_kernel"],"id":"metropolitan-banking","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"strange-purse","outputId":"7a52b61a-c3e9-4c1d-f4f2-5f5854ab29a1"},"source":["# Run similarity between two strings\n","t0 = time.time()\n","# k = substring_similarity(\"ATGCATGATGCATG\", \"ATGCATCATGATGT\", 3, 1.)\n","# k = substring_similarity(\"ATGC\", \"ATGC\", 3, 0.7)\n","k = substring_similarity(\"cat\", \"cat\", 1, 0.7)\n","k_expected = 2 * 0.7 ** 4 + 0.7 ** 6\n","print(f\"Time to compute : {time.time() - t0:.4f}s\")\n","print(f\"Value : {k}\")\n","print(f\"Expected value : {k_expected}\")"],"id":"strange-purse","execution_count":null,"outputs":[{"output_type":"stream","text":["Time to compute : 2.0617s\n","Value : 0.9799999999999999\n","Expected value : 0.5978489999999999\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"premier-modern","outputId":"6ae87ab4-9256-4e02-8d79-c208210f80a0"},"source":["# Run kernel computation between N strings\n","X = pd.read_csv(f'{data_folder}/Xtr0.csv', sep = ',').to_numpy()\n","X = X[:100,1]\n","t0 = time.time()\n","K = substring_kernel(X, X, k=5, lambd=0.7)\n","print(f\"Time to compute K : {time.time() - t0:.2f}s\")\n","# print(K)"],"id":"premier-modern","execution_count":null,"outputs":[{"output_type":"stream","text":["Time to compute K : 76.18s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"imported-pontiac"},"source":["## D) Mismatch kernel"],"id":"imported-pontiac"},{"cell_type":"code","metadata":{"id":"acoustic-girlfriend"},"source":["from kernels import Mismatch_kernel"],"id":"acoustic-girlfriend","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"piano-medication"},"source":["# Example when using a precomputed kernel\n","K = []\n","k=9\n","m=4\n","for name in [0, 1, 2]:\n","    X    = np.array(pd.read_csv(f'{data_folder}/Xtr{name}.csv')['seq'])\n","    X_ev = np.array(pd.read_csv(f'{data_folder}/Xte{name}.csv')['seq'])\n","    \n","    t0 = time.time()\n","    K_tr = Mismatch_kernel(X, X, k=k, m=m)\n","    np.save('results/dataset_{}_mismatch_K_tr_{}_{}.npy'.format(name,k,m), K_tr)\n","    print(f\"Time to compute train kernel : {time.time() - t0}\")\n","    K_te = Mismatch_kernel(X, X_ev, k=k, m=m)\n","    np.save('results/dataset_{}_mismatch_K_te_{}_{}.npy'.format(name,k,m), K_te)\n","\n","    \n","    K.append({\"train\": K_tr, \"eval\": K_te})"],"id":"piano-medication","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FhtG9maPgmp8"},"source":["kernels = [[6,2],[7,3]]\n","\n","K=[]\n","for name in [0,1,2]:\n","    K_tr = 0\n","    K_te = 0\n","    for kernel in kernels:\n","        K_tr = K_tr + np.load('results/dataset_{}_mismatch_K_tr_{}_{}.npy'.format(name,kernel[0],kernel[1]))\n","        K_te = K_te + np.load('results/dataset_{}_mismatch_K_te_{}_{}.npy'.format(name,kernel[0],kernel[1]))\n","    K.append({\"train\": K_tr, \"eval\": K_te})"],"id":"FhtG9maPgmp8","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"global-vertical","outputId":"6e2b5541-2366-417f-c2dd-8fa57568e3fd"},"source":["y_eval = run_model('ksvm', kernel='mismatch', K=K, sequence=True, prop_test=0.3)"],"id":"global-vertical","execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy on train set 0: 0.97\n","Accuracy on test set 0 : 0.66\n","Accuracy on train set 1: 0.98\n","Accuracy on test set 1 : 0.63\n","Accuracy on train set 2: 0.98\n","Accuracy on test set 2 : 0.75\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vanilla-marine"},"source":["ids = np.arange(y_eval.shape[0])\n","filename = \"results/submission_sum_mismatch_7_3_6_2_lamb=10.csv\"\n","write_csv(ids, y_eval, filename)"],"id":"vanilla-marine","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mKACO0Kq6GM3"},"source":["## E) Fisher kernel"],"id":"mKACO0Kq6GM3"},{"cell_type":"code","metadata":{"id":"_hSkeEys6tCF","executionInfo":{"status":"ok","timestamp":1616594214758,"user_tz":-60,"elapsed":783,"user":{"displayName":"Julia Linhart","photoUrl":"","userId":"01343193259563128268"}}},"source":["from utils import init_model, run_model\n","from kernels import spectrum_matrix, emission_probs, Fisher_kernel"],"id":"_hSkeEys6tCF","execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"impressive-russia","executionInfo":{"status":"ok","timestamp":1616594219303,"user_tz":-60,"elapsed":4052,"user":{"displayName":"Julia Linhart","photoUrl":"","userId":"01343193259563128268"}}},"source":["data_folder = 'data'\n","\n","X_pos = []\n","\n","for name in [0,1,2]:\n","  X = pd.read_csv(f'{data_folder}/Xtr{name}.csv')\n","  X = np.array(X['seq'])\n","  y = pd.read_csv(f'{data_folder}/Ytr{name}.csv')\n","  y = np.array(y['Bound'])\n","  df = pd.DataFrame({'Sequence':X,'Label':y})\n","  X_pos.append(np.array(df[df['Label']==1]['Sequence']))\n","\n","X_pos0 = X_pos[0]\n","X_pos1 = X_pos[1]\n","X_pos2 = X_pos[2]"],"id":"impressive-russia","execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjybwEBw6OQn"},"source":["#precompute kernel \n","K = []\n","for name in [0, 1, 2]:\n","    X    = np.array(pd.read_csv(f'{data_folder}/Xtr{name}.csv')['seq'])\n","    X_ev = np.array(pd.read_csv(f'{data_folder}/Xte{name}.csv')['seq'])\n","    \n","    t0 = time.time()\n","    K_tr = Fisher_kernel(X, X,X_pos[name], k=5)\n","    print(f\"Time to compute train kernel : {time.time() - t0}\")\n","    K_te = Fisher_kernel(X, X_ev, X_pos[name], k=5)\n","    \n","    K.append({\"train\": K_tr, \"eval\": K_te})\n","\n","for name in [0, 1, 2]:\n","  K[name]['train'] = K_tr+10e-8*np.eye(K_tr.shape[0])\n","\n","\n","np.save('fisher_kernels_k5_alldata.npy',K)"],"id":"tjybwEBw6OQn","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TE5N4KnM7MdW","executionInfo":{"elapsed":64267,"status":"ok","timestamp":1615223864593,"user":{"displayName":"Julia Linhart","photoUrl":"","userId":"01343193259563128268"},"user_tz":-60},"outputId":"83a0f07c-1562-485e-c51b-cd735544becf"},"source":["default_params = {'lamb': 15, 'sigma': 1.2, 'k': [5]}\n","y_eval = run_model('ksvm', kernel='fisher', K=K, sequence=True, prop_test=0.001,default_params=default_params)"],"id":"TE5N4KnM7MdW","execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy on train set 0: 0.53\n","Accuracy on test set 0 : 0.50\n","Accuracy on train set 1: 0.52\n","Accuracy on test set 1 : 0.50\n","Accuracy on train set 2: 0.52\n","Accuracy on test set 2 : 0.50\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"v99LHMaICHsL"},"source":["## F) TF-IDF representation of data"],"id":"v99LHMaICHsL"},{"cell_type":"code","metadata":{"id":"ytY_kZZVgmqC"},"source":["from kernels import Gaussian_kernel, compute_TFIDF"],"id":"ytY_kZZVgmqC","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tLqdAzXXgmqC","outputId":"b6477475-7454-42f9-ac0d-50725a6289f5"},"source":["data_folder = \"data\"\n","\n","K = []\n","\n","for name in [0, 1, 2]:\n","    X    = np.array(pd.read_csv(f'{data_folder}/Xtr{name}.csv')['seq'])\n","    X_ev = np.array(pd.read_csv(f'{data_folder}/Xte{name}.csv')['seq'])\n","    \n","    X_tfidf, idf = compute_TFIDF(X, k=3, bool_return_idf=True)\n","    X_tfidf_ev = compute_TFIDF(X_ev, k=3, idf=idf)\n","    \n","    t0 = time.time()\n","    K_tr = Gaussian_kernel(X_tfidf, X_tfidf, sig=0.5)\n","    print(f\"Time to compute train kernel : {time.time() - t0}\")\n","    K_te = Gaussian_kernel(X_tfidf, X_tfidf_ev, sig=0.5)\n","\n","    \n","    K.append({\"train\": K_tr, \"eval\": K_te})"],"id":"tLqdAzXXgmqC","execution_count":null,"outputs":[{"output_type":"stream","text":["Time to compute train kernel : 2.443631172180176\n","Time to compute train kernel : 2.4078073501586914\n","Time to compute train kernel : 2.467449188232422\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hnueT3jggmqD","outputId":"5baea5db-f040-4462-cead-3f6276367364"},"source":["default_params = {\"lamb\": 10000}\n","\n","run_model('ksvm', kernel='gaussian', K=K, sequence=True, prop_test=0.2, default_params=default_params)"],"id":"hnueT3jggmqD","execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy on train set 0: 0.93\n","Accuracy on test set 0 : 0.50\n","Accuracy on train set 1: 0.67\n","Accuracy on test set 1 : 0.50\n","Accuracy on train set 2: 1.00\n","Accuracy on test set 2 : 0.62\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([ 1, -1, -1, ..., -1, -1, -1])"]},"metadata":{"tags":[]},"execution_count":70}]},{"cell_type":"markdown","metadata":{"id":"8nlTDnvagmqD"},"source":["### G) Simple MKL"],"id":"8nlTDnvagmqD"},{"cell_type":"code","metadata":{"id":"12P5GrBCgmqD"},"source":["from kernels import Spectrum_kernel\n","from kernel_models import KernelSVM\n","from utils import load_precomputed_kernel"],"id":"12P5GrBCgmqD","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"agmKYU7XgmqE","outputId":"817bd689-9a62-4bde-aeae-4e860fcba81b"},"source":["# Example when using a precomputed kernel\n","K = [{\"train\": [], \"eval\": []} for _ in range(3)]\n","for name in [0, 1, 2]:\n","    X    = np.array(pd.read_csv(f'{data_folder}/Xtr{name}.csv')['seq'])\n","    X_ev = np.array(pd.read_csv(f'{data_folder}/Xte{name}.csv')['seq'])\n","    \n","    t0 = time.time()\n","    K_tr = Spectrum_kernel(X, X, k=6)\n","    print(f\"Time to compute train kernel : {time.time() - t0:.2f}s\")\n","    K_te = Spectrum_kernel(X, X_ev, k=6)\n","    \n","    K[name][\"train\"].append(K_tr)\n","    K[name][\"eval\"].append(K_te)\n","    \n","# Example when using a precomputed kernel\n","for name in [0, 1, 2]:\n","    X    = np.array(pd.read_csv(f'{data_folder}/Xtr{name}.csv')['seq'])\n","    X_ev = np.array(pd.read_csv(f'{data_folder}/Xte{name}.csv')['seq'])\n","    \n","    t0 = time.time()\n","    K_tr = Spectrum_kernel(X, X, k=4)\n","    print(f\"Time to compute train kernel : {time.time() - t0:.2f}s\")\n","    K_te = Spectrum_kernel(X, X_ev, k=4)\n","    \n","    K[name][\"train\"].append(K_tr)\n","    K[name][\"eval\"].append(K_te)"],"id":"agmKYU7XgmqE","execution_count":null,"outputs":[{"output_type":"stream","text":["Time to compute train kernel : 0.6205132007598877\n","Time to compute train kernel : 0.5754609107971191\n","Time to compute train kernel : 0.6791849136352539\n","Time to compute train kernel : 0.333111047744751\n","Time to compute train kernel : 0.32512974739074707\n","Time to compute train kernel : 0.29919910430908203\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6oKMKFdCgmqE","outputId":"90d15123-345e-454e-8190-284775c6c29a"},"source":["default_params = {\"lamb\": 10, \"step\": .1}\n","\n","run_model('ksvm', kernel='', K=K, sequence=True, prop_test=0.2, default_params=default_params, use_mkl=True, mkl_iterations=1)"],"id":"6oKMKFdCgmqE","execution_count":null,"outputs":[{"output_type":"stream","text":["Optimal weights for kernels: [0.44280158 0.55719842]\n","Accuracy on train set 0: 0.53\n","Accuracy on test set 0 : 0.49\n","\n","Optimal weights for kernels: [0.44517662 0.55482338]\n","Accuracy on train set 1: 0.68\n","Accuracy on test set 1 : 0.59\n","\n","Optimal weights for kernels: [0.44167899 0.55832101]\n","Accuracy on train set 2: 0.73\n","Accuracy on test set 2 : 0.68\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([-1, -1, -1, ..., -1, -1,  1])"]},"metadata":{"tags":[]},"execution_count":103}]}]}