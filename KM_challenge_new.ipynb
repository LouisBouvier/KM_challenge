{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "trained-treatment",
   "metadata": {
    "id": "trained-treatment"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/MyDrive/MVA/KKML')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-fifteen",
   "metadata": {
    "id": "joint-fifteen"
   },
   "source": [
    "# Kernel Methods: Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-amino",
   "metadata": {
    "id": "forty-amino"
   },
   "source": [
    "Julia Linhart, Roman Castagné, Louis Bouvier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "engaging-exception",
   "metadata": {
    "id": "engaging-exception"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import cvxpy as cp\n",
    "import warnings\n",
    "import time\n",
    "from itertools import product\n",
    "from numba import jit\n",
    "\n",
    "from utils import run_model, write_csv\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-teacher",
   "metadata": {
    "id": "understanding-teacher"
   },
   "source": [
    "# I) Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "accessory-consultation",
   "metadata": {
    "id": "accessory-consultation"
   },
   "outputs": [],
   "source": [
    "data_folder = 'data' # 'machine-learning-with-kernel-methods-2021'\n",
    "\n",
    "X_train_1 = pd.read_csv(f'{data_folder}/Xtr2_mat100.csv', sep = ' ', index_col=False, header=None)\n",
    "y_train_1 = pd.read_csv(f'{data_folder}/Ytr2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "horizontal-uzbekistan",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "horizontal-uzbekistan",
    "outputId": "86484a12-74fd-48c5-ba20-673c64dde0b9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4999.500000</td>\n",
       "      <td>0.498500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>577.494589</td>\n",
       "      <td>0.500123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4499.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4999.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5499.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id        Bound\n",
       "count  2000.000000  2000.000000\n",
       "mean   4999.500000     0.498500\n",
       "std     577.494589     0.500123\n",
       "min    4000.000000     0.000000\n",
       "25%    4499.750000     0.000000\n",
       "50%    4999.500000     0.000000\n",
       "75%    5499.250000     1.000000\n",
       "max    5999.000000     1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "violent-people",
   "metadata": {
    "id": "violent-people"
   },
   "outputs": [],
   "source": [
    "y_train_1 = np.array(y_train_1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "synthetic-rainbow",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "synthetic-rainbow",
    "outputId": "239063d5-fecd-4f52-ec50-21bad3cfc36d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.010565</td>\n",
       "      <td>0.010201</td>\n",
       "      <td>0.010375</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.011609</td>\n",
       "      <td>0.010707</td>\n",
       "      <td>0.009359</td>\n",
       "      <td>0.011957</td>\n",
       "      <td>0.009571</td>\n",
       "      <td>0.010582</td>\n",
       "      <td>0.009424</td>\n",
       "      <td>0.009793</td>\n",
       "      <td>0.012848</td>\n",
       "      <td>0.012092</td>\n",
       "      <td>0.011196</td>\n",
       "      <td>0.010364</td>\n",
       "      <td>0.009875</td>\n",
       "      <td>0.010962</td>\n",
       "      <td>0.010185</td>\n",
       "      <td>0.008342</td>\n",
       "      <td>0.010734</td>\n",
       "      <td>0.010038</td>\n",
       "      <td>0.011554</td>\n",
       "      <td>0.008995</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.008886</td>\n",
       "      <td>0.008826</td>\n",
       "      <td>0.007821</td>\n",
       "      <td>0.009761</td>\n",
       "      <td>0.008533</td>\n",
       "      <td>0.011864</td>\n",
       "      <td>0.009299</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>0.009560</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.010217</td>\n",
       "      <td>0.009641</td>\n",
       "      <td>0.009880</td>\n",
       "      <td>0.010038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009511</td>\n",
       "      <td>0.010614</td>\n",
       "      <td>0.011957</td>\n",
       "      <td>0.009641</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>0.010005</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>0.010587</td>\n",
       "      <td>0.009793</td>\n",
       "      <td>0.010908</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.009772</td>\n",
       "      <td>0.009103</td>\n",
       "      <td>0.010147</td>\n",
       "      <td>0.008587</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.010897</td>\n",
       "      <td>0.008913</td>\n",
       "      <td>0.008630</td>\n",
       "      <td>0.008380</td>\n",
       "      <td>0.009016</td>\n",
       "      <td>0.011478</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.009989</td>\n",
       "      <td>0.010587</td>\n",
       "      <td>0.008625</td>\n",
       "      <td>0.007951</td>\n",
       "      <td>0.009457</td>\n",
       "      <td>0.008554</td>\n",
       "      <td>0.009283</td>\n",
       "      <td>0.008261</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>0.011141</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>0.008217</td>\n",
       "      <td>0.008565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012278</td>\n",
       "      <td>0.010723</td>\n",
       "      <td>0.011467</td>\n",
       "      <td>0.011453</td>\n",
       "      <td>0.012182</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>0.009789</td>\n",
       "      <td>0.012444</td>\n",
       "      <td>0.013805</td>\n",
       "      <td>0.013652</td>\n",
       "      <td>0.012934</td>\n",
       "      <td>0.011163</td>\n",
       "      <td>0.027178</td>\n",
       "      <td>0.018160</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.010356</td>\n",
       "      <td>0.010089</td>\n",
       "      <td>0.019951</td>\n",
       "      <td>0.010631</td>\n",
       "      <td>0.009920</td>\n",
       "      <td>0.011238</td>\n",
       "      <td>0.010962</td>\n",
       "      <td>0.011475</td>\n",
       "      <td>0.009723</td>\n",
       "      <td>0.010922</td>\n",
       "      <td>0.009933</td>\n",
       "      <td>0.009622</td>\n",
       "      <td>0.009861</td>\n",
       "      <td>0.010099</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.009945</td>\n",
       "      <td>0.010829</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.010460</td>\n",
       "      <td>0.011039</td>\n",
       "      <td>0.009612</td>\n",
       "      <td>0.010705</td>\n",
       "      <td>0.012258</td>\n",
       "      <td>0.020208</td>\n",
       "      <td>0.011266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010436</td>\n",
       "      <td>0.011172</td>\n",
       "      <td>0.012915</td>\n",
       "      <td>0.010912</td>\n",
       "      <td>0.011305</td>\n",
       "      <td>0.016977</td>\n",
       "      <td>0.014644</td>\n",
       "      <td>0.012108</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.009647</td>\n",
       "      <td>0.011868</td>\n",
       "      <td>0.011752</td>\n",
       "      <td>0.013102</td>\n",
       "      <td>0.010237</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>0.009687</td>\n",
       "      <td>0.011871</td>\n",
       "      <td>0.010457</td>\n",
       "      <td>0.012348</td>\n",
       "      <td>0.011010</td>\n",
       "      <td>0.011005</td>\n",
       "      <td>0.010695</td>\n",
       "      <td>0.009248</td>\n",
       "      <td>0.010494</td>\n",
       "      <td>0.009279</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>0.015973</td>\n",
       "      <td>0.009745</td>\n",
       "      <td>0.011904</td>\n",
       "      <td>0.009605</td>\n",
       "      <td>0.009701</td>\n",
       "      <td>0.009350</td>\n",
       "      <td>0.009741</td>\n",
       "      <td>0.012341</td>\n",
       "      <td>0.010338</td>\n",
       "      <td>0.010863</td>\n",
       "      <td>0.010402</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.009283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.097826</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.097826</td>\n",
       "      <td>0.184783</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.141304</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.141304</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.097826</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.119565</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.141304</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.119565</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.119565</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.097826</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.097826</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1   ...           98           99\n",
       "count  2000.000000  2000.000000  ...  2000.000000  2000.000000\n",
       "mean      0.010565     0.010201  ...     0.008217     0.008565\n",
       "std       0.012278     0.010723  ...     0.009709     0.009283\n",
       "min       0.000000     0.000000  ...     0.000000     0.000000\n",
       "25%       0.000000     0.000000  ...     0.000000     0.000000\n",
       "50%       0.010870     0.010870  ...     0.010870     0.010870\n",
       "75%       0.010870     0.021739  ...     0.010870     0.010870\n",
       "max       0.086957     0.065217  ...     0.065217     0.043478\n",
       "\n",
       "[8 rows x 100 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-condition",
   "metadata": {
    "id": "european-condition"
   },
   "outputs": [],
   "source": [
    "X_train_1 = np.array(X_train_1)\n",
    "X_train_1 = (X_train_1 - X_train_1.mean(axis=0))/X_train_1.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-refund",
   "metadata": {
    "id": "public-refund"
   },
   "source": [
    "# II) First linear models of the mat100 input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-moral",
   "metadata": {
    "id": "express-moral"
   },
   "source": [
    "## A) Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "iP9HPOCOcl9X",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iP9HPOCOcl9X",
    "outputId": "92650470-a6b5-46b8-8808-ce62ef26e537"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/MVA/KKML/functions.py:103: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  inv_hess, _, _, _ = np.linalg.lstsq(hess, np.eye(hess.shape[0]))\n",
      "/content/drive/My Drive/MVA/KKML/functions.py:111: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  inv_hess, _, _, _ = np.linalg.lstsq(hess, np.eye(hess.shape[0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set 0: 0.62\n",
      "Accuracy on test set 0 : 0.56\n",
      "Accuracy on train set 1: 0.60\n",
      "Accuracy on test set 1 : 0.59\n",
      "Accuracy on train set 2: 0.70\n",
      "Accuracy on test set 2 : 0.66\n"
     ]
    }
   ],
   "source": [
    "from utils import run_model\n",
    "\n",
    "run_model('logreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-dominant",
   "metadata": {
    "id": "liberal-dominant",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import write_csv\n",
    "\n",
    "ids = np.arange(all_y_eval.shape[0])\n",
    "filename = \"results/submission_log_reg.csv\"\n",
    "\n",
    "# write_csv(ids, all_y_eval, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-algebra",
   "metadata": {
    "id": "careful-algebra"
   },
   "source": [
    "## B) Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8JZGxc7Ye0Zf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8JZGxc7Ye0Zf",
    "outputId": "a8e42c29-bb95-42cb-a4e8-093a9b6dc4c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set 0: 0.65\n",
      "Accuracy on test set 0 : 0.60\n",
      "Accuracy on train set 1: 0.64\n",
      "Accuracy on test set 1 : 0.57\n",
      "Accuracy on train set 2: 0.73\n",
      "Accuracy on test set 2 : 0.69\n"
     ]
    }
   ],
   "source": [
    "run_model('rr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-combining",
   "metadata": {
    "id": "twenty-combining"
   },
   "source": [
    "# III) Kernel baselines "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-council",
   "metadata": {
    "id": "twelve-council"
   },
   "source": [
    "## A) Gaussian Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-rouge",
   "metadata": {
    "id": "employed-rouge"
   },
   "source": [
    "### a) Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "jlx_YAu_fYEv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jlx_YAu_fYEv",
    "outputId": "125e6fc4-ae04-4a84-be5f-0a094309014f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'gaussian', 'lamb': 0.1, 'sigma': 0.5789473684210527}\n",
      "Accuracy on train set 0: 1.00\n",
      "Accuracy on test set 0 : 0.57\n",
      "{'kernel': 'gaussian', 'lamb': 0.1, 'sigma': 0.6578947368421053}\n",
      "Accuracy on train set 1: 1.00\n",
      "Accuracy on test set 1 : 0.59\n",
      "{'kernel': 'gaussian', 'lamb': 0.1, 'sigma': 0.5}\n",
      "Accuracy on train set 2: 1.00\n",
      "Accuracy on test set 2 : 0.67\n"
     ]
    }
   ],
   "source": [
    "## run kernel ridge regression with gaussian kernel\n",
    "run_model('krr',kernel='gaussian',prop_test=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-daisy",
   "metadata": {
    "id": "occupied-daisy"
   },
   "source": [
    "### b) Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7UaoFt6WgMg7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7UaoFt6WgMg7",
    "outputId": "fb2f6572-8915-430a-962f-ae6f53f40a63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'gaussian', 'lamb': 1e-07, 'sigma': 100.0}\n",
      "Accuracy on train set 0: 0.99\n",
      "Accuracy on test set 0 : 0.62\n",
      "{'kernel': 'gaussian', 'lamb': 1e-10, 'sigma': 1.0}\n",
      "Accuracy on train set 1: 1.00\n",
      "Accuracy on test set 1 : 0.60\n",
      "{'kernel': 'gaussian', 'lamb': 1e-07, 'sigma': 100.0}\n",
      "Accuracy on train set 2: 0.99\n",
      "Accuracy on test set 2 : 0.72\n"
     ]
    }
   ],
   "source": [
    "## run kernel SVM with gaussian kernel\n",
    "run_model('ksvm',kernel='gaussian',prop_test=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R1tFJMYGhoP1",
   "metadata": {
    "id": "R1tFJMYGhoP1"
   },
   "source": [
    "## B) Spectrum kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5gtqIIBzhnpv",
   "metadata": {
    "id": "5gtqIIBzhnpv"
   },
   "outputs": [],
   "source": [
    "from kernels import Spectrum_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g2ulzuB5gSjL",
   "metadata": {
    "id": "g2ulzuB5gSjL"
   },
   "outputs": [],
   "source": [
    "## run kernel SVM with gaussian kernel\n",
    "run_model('ksvm',kernel='spectrum',sequence=True,prop_test=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ou8DGpwRhznF",
   "metadata": {
    "id": "ou8DGpwRhznF"
   },
   "source": [
    "### a) Kernel SVM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-mechanism",
   "metadata": {
    "id": "honest-mechanism"
   },
   "source": [
    "## C) Substring kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "WoRJXre-Yvf5",
   "metadata": {
    "id": "WoRJXre-Yvf5"
   },
   "outputs": [],
   "source": [
    "from kernels import substring_similarity, substring_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "imposed-professional",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imposed-professional",
    "outputId": "7a52b61a-c3e9-4c1d-f4f2-5f5854ab29a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute : 2.0617s\n",
      "Value : 0.9799999999999999\n",
      "Expected value : 0.5978489999999999\n"
     ]
    }
   ],
   "source": [
    "# Run similarity between two strings\n",
    "t0 = time.time()\n",
    "# k = substring_similarity(\"ATGCATGATGCATG\", \"ATGCATCATGATGT\", 3, 1.)\n",
    "# k = substring_similarity(\"ATGC\", \"ATGC\", 3, 0.7)\n",
    "k = substring_similarity(\"cat\", \"cat\", 1, 0.7)\n",
    "k_expected = 2 * 0.7 ** 4 + 0.7 ** 6\n",
    "print(f\"Time to compute : {time.time() - t0:.4f}s\")\n",
    "print(f\"Value : {k}\")\n",
    "print(f\"Expected value : {k_expected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fantastic-boston",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fantastic-boston",
    "outputId": "6ae87ab4-9256-4e02-8d79-c208210f80a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute K : 76.18s\n"
     ]
    }
   ],
   "source": [
    "# Run kernel computation between N strings\n",
    "X = pd.read_csv(f'{data_folder}/Xtr0.csv', sep = ',').to_numpy()\n",
    "X = X[:100,1]\n",
    "t0 = time.time()\n",
    "K = substring_kernel(X, X, k=5, lambd=0.7)\n",
    "print(f\"Time to compute K : {time.time() - t0:.2f}s\")\n",
    "# print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-going",
   "metadata": {
    "id": "certified-going"
   },
   "source": [
    "## D) Mismatch kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "comfortable-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from kernels import spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "animated-dynamics",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = [\"A\", \"T\", \"G\", \"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "complete-transportation",
   "metadata": {
    "id": "complete-transportation"
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, parent, letter):\n",
    "        self.parent = parent\n",
    "        self.letter = letter\n",
    "        self.sequence = None\n",
    "        self.pointers = {}\n",
    "        \n",
    "    def get_sequence(self):\n",
    "        return self.sequence\n",
    "    \n",
    "    def get_parent(self):\n",
    "        return self.parent\n",
    "    \n",
    "    def get_pointers(self):\n",
    "        return self.pointers\n",
    "    \n",
    "    def set_sequence(self):\n",
    "        if self.parent:\n",
    "            self.sequence = self.parent.get_sequence()+self.letter if self.parent.get_sequence() else self.letter\n",
    "    \n",
    "    def set_pointers(self, dataset, depth, max_mismatch):\n",
    "        Pointers = {}\n",
    "        if self.get_parent() is not None:\n",
    "            parent_Pointers = self.get_parent().get_pointers()\n",
    "            for pointer, mismatch in zip(parent_Pointers.keys(), parent_Pointers.values()): \n",
    "                if dataset[pointer][depth]!=self.letter:\n",
    "                    new_mismatch = mismatch+1\n",
    "                    if new_mismatch <= max_mismatch:\n",
    "                        Pointers[pointer] = new_mismatch\n",
    "                else:\n",
    "                    Pointers[pointer] = mismatch\n",
    "        else:\n",
    "            for i in range(len(dataset)):\n",
    "                Pointers[i] = 0\n",
    "        self.pointers = Pointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "exciting-islam",
   "metadata": {
    "id": "exciting-islam"
   },
   "outputs": [],
   "source": [
    "class Tree(Node):\n",
    "    def __init__(self,k,m,dataset):\n",
    "        self.maxdepth = k\n",
    "        self.max_nb_mismatches = m\n",
    "        # create the strings of length k with the alphabet\n",
    "        self.dataset = dataset\n",
    "        # create the root node with no letter and no parent\n",
    "        root = Node(parent=None, letter=None)\n",
    "        root.set_pointers(self.dataset, 0, self.max_nb_mismatches)\n",
    "        # create a dictionnary of nodes: width first\n",
    "        self.Nodes = {'0': [root]}\n",
    "        for d in range(1,self.maxdepth+1):\n",
    "            self.Nodes[str(d)] = []\n",
    "        count=0\n",
    "        while count<self.maxdepth:\n",
    "            for parent_ in self.Nodes[str(count)]:\n",
    "                for charact in alphabet:\n",
    "                    child = Node(parent_,charact)\n",
    "                    child.set_pointers(self.dataset, count, self.max_nb_mismatches)\n",
    "                    self.Nodes[str(count+1)].append(child)\n",
    "            count+=1                \n",
    "            \n",
    "    def get_Nodes(self):\n",
    "        return self.Nodes\n",
    "    \n",
    "    def build_kernel(self):\n",
    "        nb_substrings_per_string = 101-self.maxdepth+1\n",
    "        samples = self.dataset.reshape(-1,nb_substrings_per_string)\n",
    "        print(samples.shape)\n",
    "        K = np.zeros((samples.shape[0], samples.shape[0]))\n",
    "        for leaf in self.Nodes[str(self.maxdepth)]:\n",
    "            one_hot = np.zeros(len(self.dataset))\n",
    "            one_hot[list(leaf.get_pointers().keys())]=1\n",
    "            occurences = one_hot.reshape(-1,nb_substrings_per_string).sum(axis=1)\n",
    "            K = K + occurences.T@occurences\n",
    "        return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "banner-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6\n",
    "m = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "interior-looking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 96)\n",
      "(2000,)\n",
      "['TCCTGT' 'CCTGTG' 'CTGTGC' ... 'GCCCTC' 'CCCTCC' 'CCTCCC']\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv(f'{data_folder}/Xtr0.csv', sep = ',').to_numpy()\n",
    "y = pd.read_csv(f'{data_folder}/ytr0.csv', sep = ',').to_numpy()[:,1]\n",
    "sequences = X[:,1]\n",
    "dataset_k = np.array([spectrum(x,k) for x in sequences])\n",
    "print(dataset_k.shape)\n",
    "print(y.shape)\n",
    "dataset_k = dataset_k.reshape(-1)\n",
    "print(dataset_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "serial-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_tree = Tree(k=k,m=m, dataset=dataset_k)\n",
    "dict_Nodes = Test_tree.get_Nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "pointed-diagram",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 96)\n"
     ]
    }
   ],
   "source": [
    "kernel = Test_tree.build_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "empty-infrared",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.9415845100507453e-05\n"
     ]
    }
   ],
   "source": [
    "print(np.amin(np.linalg.eig(kernel)[0].real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-induction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "KM_challenge_new.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
