{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "trained-treatment"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/MyDrive/MVA/KKML')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joint-fifteen"
   },
   "source": [
    "# Kernel Methods: Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "forty-amino"
   },
   "source": [
    "Julia Linhart, Roman Castagné, Louis Bouvier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "engaging-exception"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import cvxpy as cp\n",
    "import warnings\n",
    "import time\n",
    "from itertools import product\n",
    "from numba import jit\n",
    "\n",
    "from utils import run_model, write_csv\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "understanding-teacher"
   },
   "source": [
    "# I) Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "accessory-consultation"
   },
   "outputs": [],
   "source": [
    "data_folder = 'data' # 'machine-learning-with-kernel-methods-2021'\n",
    "\n",
    "X_train_1 = pd.read_csv(f'{data_folder}/Xtr2_mat100.csv', sep = ' ', index_col=False, header=None)\n",
    "y_train_1 = pd.read_csv(f'{data_folder}/Ytr2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "horizontal-uzbekistan",
    "outputId": "86484a12-74fd-48c5-ba20-673c64dde0b9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4999.500000</td>\n",
       "      <td>0.498500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>577.494589</td>\n",
       "      <td>0.500123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4499.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4999.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5499.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id        Bound\n",
       "count  2000.000000  2000.000000\n",
       "mean   4999.500000     0.498500\n",
       "std     577.494589     0.500123\n",
       "min    4000.000000     0.000000\n",
       "25%    4499.750000     0.000000\n",
       "50%    4999.500000     0.000000\n",
       "75%    5499.250000     1.000000\n",
       "max    5999.000000     1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "violent-people"
   },
   "outputs": [],
   "source": [
    "y_train_1 = np.array(y_train_1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "synthetic-rainbow",
    "outputId": "239063d5-fecd-4f52-ec50-21bad3cfc36d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.010565</td>\n",
       "      <td>0.010201</td>\n",
       "      <td>0.010375</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.011609</td>\n",
       "      <td>0.010707</td>\n",
       "      <td>0.009359</td>\n",
       "      <td>0.011957</td>\n",
       "      <td>0.009571</td>\n",
       "      <td>0.010582</td>\n",
       "      <td>0.009424</td>\n",
       "      <td>0.009793</td>\n",
       "      <td>0.012848</td>\n",
       "      <td>0.012092</td>\n",
       "      <td>0.011196</td>\n",
       "      <td>0.010364</td>\n",
       "      <td>0.009875</td>\n",
       "      <td>0.010962</td>\n",
       "      <td>0.010185</td>\n",
       "      <td>0.008342</td>\n",
       "      <td>0.010734</td>\n",
       "      <td>0.010038</td>\n",
       "      <td>0.011554</td>\n",
       "      <td>0.008995</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.008886</td>\n",
       "      <td>0.008826</td>\n",
       "      <td>0.007821</td>\n",
       "      <td>0.009761</td>\n",
       "      <td>0.008533</td>\n",
       "      <td>0.011864</td>\n",
       "      <td>0.009299</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>0.009560</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.010217</td>\n",
       "      <td>0.009641</td>\n",
       "      <td>0.009880</td>\n",
       "      <td>0.010038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009511</td>\n",
       "      <td>0.010614</td>\n",
       "      <td>0.011957</td>\n",
       "      <td>0.009641</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>0.010005</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>0.010587</td>\n",
       "      <td>0.009793</td>\n",
       "      <td>0.010908</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.009772</td>\n",
       "      <td>0.009103</td>\n",
       "      <td>0.010147</td>\n",
       "      <td>0.008587</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.010897</td>\n",
       "      <td>0.008913</td>\n",
       "      <td>0.008630</td>\n",
       "      <td>0.008380</td>\n",
       "      <td>0.009016</td>\n",
       "      <td>0.011478</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.009989</td>\n",
       "      <td>0.010587</td>\n",
       "      <td>0.008625</td>\n",
       "      <td>0.007951</td>\n",
       "      <td>0.009457</td>\n",
       "      <td>0.008554</td>\n",
       "      <td>0.009283</td>\n",
       "      <td>0.008261</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>0.011141</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>0.008217</td>\n",
       "      <td>0.008565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012278</td>\n",
       "      <td>0.010723</td>\n",
       "      <td>0.011467</td>\n",
       "      <td>0.011453</td>\n",
       "      <td>0.012182</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>0.009789</td>\n",
       "      <td>0.012444</td>\n",
       "      <td>0.013805</td>\n",
       "      <td>0.013652</td>\n",
       "      <td>0.012934</td>\n",
       "      <td>0.011163</td>\n",
       "      <td>0.027178</td>\n",
       "      <td>0.018160</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.010356</td>\n",
       "      <td>0.010089</td>\n",
       "      <td>0.019951</td>\n",
       "      <td>0.010631</td>\n",
       "      <td>0.009920</td>\n",
       "      <td>0.011238</td>\n",
       "      <td>0.010962</td>\n",
       "      <td>0.011475</td>\n",
       "      <td>0.009723</td>\n",
       "      <td>0.010922</td>\n",
       "      <td>0.009933</td>\n",
       "      <td>0.009622</td>\n",
       "      <td>0.009861</td>\n",
       "      <td>0.010099</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.009945</td>\n",
       "      <td>0.010829</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.010460</td>\n",
       "      <td>0.011039</td>\n",
       "      <td>0.009612</td>\n",
       "      <td>0.010705</td>\n",
       "      <td>0.012258</td>\n",
       "      <td>0.020208</td>\n",
       "      <td>0.011266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010436</td>\n",
       "      <td>0.011172</td>\n",
       "      <td>0.012915</td>\n",
       "      <td>0.010912</td>\n",
       "      <td>0.011305</td>\n",
       "      <td>0.016977</td>\n",
       "      <td>0.014644</td>\n",
       "      <td>0.012108</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.009647</td>\n",
       "      <td>0.011868</td>\n",
       "      <td>0.011752</td>\n",
       "      <td>0.013102</td>\n",
       "      <td>0.010237</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>0.009687</td>\n",
       "      <td>0.011871</td>\n",
       "      <td>0.010457</td>\n",
       "      <td>0.012348</td>\n",
       "      <td>0.011010</td>\n",
       "      <td>0.011005</td>\n",
       "      <td>0.010695</td>\n",
       "      <td>0.009248</td>\n",
       "      <td>0.010494</td>\n",
       "      <td>0.009279</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>0.015973</td>\n",
       "      <td>0.009745</td>\n",
       "      <td>0.011904</td>\n",
       "      <td>0.009605</td>\n",
       "      <td>0.009701</td>\n",
       "      <td>0.009350</td>\n",
       "      <td>0.009741</td>\n",
       "      <td>0.012341</td>\n",
       "      <td>0.010338</td>\n",
       "      <td>0.010863</td>\n",
       "      <td>0.010402</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.009283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.097826</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.097826</td>\n",
       "      <td>0.184783</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.141304</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.141304</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.097826</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.119565</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.141304</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.119565</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.119565</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.097826</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.097826</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1   ...           98           99\n",
       "count  2000.000000  2000.000000  ...  2000.000000  2000.000000\n",
       "mean      0.010565     0.010201  ...     0.008217     0.008565\n",
       "std       0.012278     0.010723  ...     0.009709     0.009283\n",
       "min       0.000000     0.000000  ...     0.000000     0.000000\n",
       "25%       0.000000     0.000000  ...     0.000000     0.000000\n",
       "50%       0.010870     0.010870  ...     0.010870     0.010870\n",
       "75%       0.010870     0.021739  ...     0.010870     0.010870\n",
       "max       0.086957     0.065217  ...     0.065217     0.043478\n",
       "\n",
       "[8 rows x 100 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "european-condition"
   },
   "outputs": [],
   "source": [
    "X_train_1 = np.array(X_train_1)\n",
    "X_train_1 = (X_train_1 - X_train_1.mean(axis=0))/X_train_1.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "public-refund"
   },
   "source": [
    "# II) First linear models of the mat100 input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "express-moral"
   },
   "source": [
    "## A) Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iP9HPOCOcl9X",
    "outputId": "92650470-a6b5-46b8-8808-ce62ef26e537"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roman\\Documents\\Academic\\2020_MVA\\S2_KernelMethods\\KM_challenge\\functions.py:103: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  inv_hess, _, _, _ = np.linalg.lstsq(hess, np.eye(hess.shape[0]))\n",
      "C:\\Users\\roman\\Documents\\Academic\\2020_MVA\\S2_KernelMethods\\KM_challenge\\functions.py:111: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  inv_hess, _, _, _ = np.linalg.lstsq(hess, np.eye(hess.shape[0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set 0: 0.62\n",
      "Accuracy on test set 0 : 0.56\n",
      "Accuracy on train set 1: 0.60\n",
      "Accuracy on test set 1 : 0.59\n",
      "Accuracy on train set 2: 0.70\n",
      "Accuracy on test set 2 : 0.66\n"
     ]
    }
   ],
   "source": [
    "from utils import run_model\n",
    "\n",
    "run_model('logreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "liberal-dominant",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import write_csv\n",
    "\n",
    "ids = np.arange(all_y_eval.shape[0])\n",
    "filename = \"results/submission_log_reg.csv\"\n",
    "\n",
    "# write_csv(ids, all_y_eval, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "careful-algebra"
   },
   "source": [
    "## B) Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8JZGxc7Ye0Zf",
    "outputId": "a8e42c29-bb95-42cb-a4e8-093a9b6dc4c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set 0: 0.65\n",
      "Accuracy on test set 0 : 0.60\n",
      "Accuracy on train set 1: 0.64\n",
      "Accuracy on test set 1 : 0.57\n",
      "Accuracy on train set 2: 0.73\n",
      "Accuracy on test set 2 : 0.69\n"
     ]
    }
   ],
   "source": [
    "run_model('rr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twenty-combining"
   },
   "source": [
    "# III) Kernel baselines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twelve-council"
   },
   "source": [
    "## A) Gaussian Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "employed-rouge"
   },
   "source": [
    "### a) Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jlx_YAu_fYEv",
    "outputId": "125e6fc4-ae04-4a84-be5f-0a094309014f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'gaussian', 'lamb': 0.1, 'sigma': 0.5789473684210527}\n",
      "Accuracy on train set 0: 1.00\n",
      "Accuracy on test set 0 : 0.57\n",
      "{'kernel': 'gaussian', 'lamb': 0.1, 'sigma': 0.6578947368421053}\n",
      "Accuracy on train set 1: 1.00\n",
      "Accuracy on test set 1 : 0.59\n",
      "{'kernel': 'gaussian', 'lamb': 0.1, 'sigma': 0.5}\n",
      "Accuracy on train set 2: 1.00\n",
      "Accuracy on test set 2 : 0.67\n"
     ]
    }
   ],
   "source": [
    "## run kernel ridge regression with gaussian kernel\n",
    "run_model('krr', kernel='gaussian', prop_test=0.2, use_grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "occupied-daisy"
   },
   "source": [
    "### b) Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7UaoFt6WgMg7",
    "outputId": "fb2f6572-8915-430a-962f-ae6f53f40a63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'gaussian', 'lamb': 1e-07, 'sigma': 100.0}\n",
      "Accuracy on train set 0: 0.99\n",
      "Accuracy on test set 0 : 0.62\n",
      "{'kernel': 'gaussian', 'lamb': 1e-10, 'sigma': 1.0}\n",
      "Accuracy on train set 1: 1.00\n",
      "Accuracy on test set 1 : 0.60\n",
      "{'kernel': 'gaussian', 'lamb': 1e-07, 'sigma': 100.0}\n",
      "Accuracy on train set 2: 0.99\n",
      "Accuracy on test set 2 : 0.72\n"
     ]
    }
   ],
   "source": [
    "## run kernel SVM with gaussian kernel\n",
    "run_model('ksvm', kernel='gaussian', prop_test=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1tFJMYGhoP1"
   },
   "source": [
    "## B) Spectrum kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5gtqIIBzhnpv"
   },
   "outputs": [],
   "source": [
    "from kernels import Spectrum_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute train kernel : 0.7150859832763672\n",
      "Time to compute train kernel : 0.6163516044616699\n",
      "Time to compute train kernel : 0.6303155422210693\n"
     ]
    }
   ],
   "source": [
    "# Example when using a precomputed kernel\n",
    "K = []\n",
    "for name in [0, 1, 2]:\n",
    "    X    = np.array(pd.read_csv(f'{data_folder}/Xtr{name}.csv')['seq'])\n",
    "    X_ev = np.array(pd.read_csv(f'{data_folder}/Xte{name}.csv')['seq'])\n",
    "    \n",
    "    t0 = time.time()\n",
    "    K_tr = Spectrum_kernel(X, X, k=6)\n",
    "    print(f\"Time to compute train kernel : {time.time() - t0}\")\n",
    "    K_te = Spectrum_kernel(X, X_ev, k=6)\n",
    "    \n",
    "    K.append({\"train\": K_tr, \"eval\": K_te})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "g2ulzuB5gSjL"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-f3adf9ba16e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## run kernel SVM with gaussian kernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrun_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ksvm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'spectrum'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprop_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Academic\\2020_MVA\\S2_KernelMethods\\KM_challenge\\utils.py\u001b[0m in \u001b[0;36mrun_model\u001b[1;34m(model_name, data_folder, prop_test, kernel, kernel_savefiles, K, sequence, use_grid_search)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;31m# Fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0muse_grid_search\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Academic\\2020_MVA\\S2_KernelMethods\\KM_challenge\\kernel_models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# The optimal objective value is returned by `prob.solve()`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[1;31m# The optimal value for x is stored in `x.value`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\problems\\problem.py\u001b[0m in \u001b[0;36msolve\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[0msolve_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProblem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_solve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msolve_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\problems\\problem.py\u001b[0m in \u001b[0;36m_solve\u001b[1;34m(self, solver, warm_start, verbose, gp, qcp, requires_grad, enforce_dpp, **kwargs)\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m         data, solving_chain, inverse_data = self.get_problem_data(\n\u001b[1;32m--> 751\u001b[1;33m             solver, gp, enforce_dpp)\n\u001b[0m\u001b[0;32m    752\u001b[0m         solution = solving_chain.solve_via_data(\n\u001b[0;32m    753\u001b[0m             self, data, warm_start, verbose, kwargs)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\problems\\problem.py\u001b[0m in \u001b[0;36mget_problem_data\u001b[1;34m(self, solver, gp, enforce_dpp)\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[0minverse_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_data\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msolver_inverse_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minverse_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolving_chain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m             safe_to_cache = (\n\u001b[0;32m    527\u001b[0m                 \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\reductions\\chain.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, problem)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0minverse_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreductions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[0mproblem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m             \u001b[0minverse_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mproblem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minverse_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\reductions\\qp2quad_form\\qp_matrix_stuffing.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, problem)\u001b[0m\n\u001b[0;32m    290\u001b[0m                                  \u001b[0mordered_cons\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                                  \u001b[0mproblem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m                                  inverse_data.param_id_map)\n\u001b[0m\u001b[0;32m    293\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnew_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minverse_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\reductions\\qp2quad_form\\qp_matrix_stuffing.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, P, q, x, A, variables, var_id_to_col, constraints, parameters, param_id_to_col, formatted)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             reduced_P, indices, indptr, shape = (\n\u001b[1;32m--> 131\u001b[1;33m                 \u001b[0mcanonInterface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_problem_data_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquad_form\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             )\n\u001b[0;32m    133\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduced_P\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduced_P\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\cvxcore\\python\\canonInterface.py\u001b[0m in \u001b[0;36mreduce_problem_data_tensor\u001b[1;34m(A, var_length, quad_form)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[0munique_old_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_coo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     old_row_to_new_row = {\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0munique_old_row\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_old_row\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m     }\n\u001b[0;32m    114\u001b[0m     \u001b[0mreduced_A_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0munique_old_row\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_coo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\cvxcore\\python\\canonInterface.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[0munique_old_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_coo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     old_row_to_new_row = {\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0munique_old_row\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_old_row\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m     }\n\u001b[0;32m    114\u001b[0m     \u001b[0mreduced_A_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0munique_old_row\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_coo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## run kernel SVM with gaussian kernel\n",
    "run_model('ksvm', kernel='spectrum', K=K, sequence=True, prop_test=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ou8DGpwRhznF"
   },
   "source": [
    "### a) Kernel SVM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "honest-mechanism"
   },
   "source": [
    "## C) Substring kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "WoRJXre-Yvf5"
   },
   "outputs": [],
   "source": [
    "from kernels import substring_similarity, substring_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imposed-professional",
    "outputId": "7a52b61a-c3e9-4c1d-f4f2-5f5854ab29a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute : 2.0617s\n",
      "Value : 0.9799999999999999\n",
      "Expected value : 0.5978489999999999\n"
     ]
    }
   ],
   "source": [
    "# Run similarity between two strings\n",
    "t0 = time.time()\n",
    "# k = substring_similarity(\"ATGCATGATGCATG\", \"ATGCATCATGATGT\", 3, 1.)\n",
    "# k = substring_similarity(\"ATGC\", \"ATGC\", 3, 0.7)\n",
    "k = substring_similarity(\"cat\", \"cat\", 1, 0.7)\n",
    "k_expected = 2 * 0.7 ** 4 + 0.7 ** 6\n",
    "print(f\"Time to compute : {time.time() - t0:.4f}s\")\n",
    "print(f\"Value : {k}\")\n",
    "print(f\"Expected value : {k_expected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fantastic-boston",
    "outputId": "6ae87ab4-9256-4e02-8d79-c208210f80a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute K : 76.18s\n"
     ]
    }
   ],
   "source": [
    "# Run kernel computation between N strings\n",
    "X = pd.read_csv(f'{data_folder}/Xtr0.csv', sep = ',').to_numpy()\n",
    "X = X[:100,1]\n",
    "t0 = time.time()\n",
    "K = substring_kernel(X, X, k=5, lambd=0.7)\n",
    "print(f\"Time to compute K : {time.time() - t0:.2f}s\")\n",
    "# print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "certified-going"
   },
   "source": [
    "## D) Mismatch kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kernels import spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = [\"A\", \"T\", \"G\", \"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "complete-transportation"
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, parent, letter):\n",
    "        self.parent = parent\n",
    "        self.letter = letter\n",
    "        self.sequence = None\n",
    "        self.pointers = {}\n",
    "        \n",
    "    def get_sequence(self):\n",
    "        return self.sequence\n",
    "    \n",
    "    def get_parent(self):\n",
    "        return self.parent\n",
    "    \n",
    "    def get_pointers(self):\n",
    "        return self.pointers\n",
    "    \n",
    "    def set_sequence(self):\n",
    "        if self.parent:\n",
    "            self.sequence = self.parent.get_sequence()+self.letter if self.parent.get_sequence() else self.letter\n",
    "    \n",
    "    def set_pointers(self, dataset, depth, max_mismatch):\n",
    "        Pointers = {}\n",
    "        if self.get_parent() is not None:\n",
    "            parent_Pointers = self.get_parent().get_pointers()\n",
    "            for pointer, mismatch in zip(parent_Pointers.keys(), parent_Pointers.values()): \n",
    "                if dataset[pointer][depth]!=self.letter:\n",
    "                    new_mismatch = mismatch+1\n",
    "                    if new_mismatch <= max_mismatch:\n",
    "                        Pointers[pointer] = new_mismatch\n",
    "                else:\n",
    "                    Pointers[pointer] = mismatch\n",
    "        else:\n",
    "            for i in range(len(dataset)):\n",
    "                Pointers[i] = 0\n",
    "        self.pointers = Pointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "exciting-islam"
   },
   "outputs": [],
   "source": [
    "class Tree(Node):\n",
    "    def __init__(self,k,m,dataset):\n",
    "        self.maxdepth = k\n",
    "        self.max_nb_mismatches = m\n",
    "        # create the strings of length k with the alphabet\n",
    "        self.dataset = dataset\n",
    "        # create the root node with no letter and no parent\n",
    "        root = Node(parent=None, letter=None)\n",
    "        root.set_pointers(self.dataset, 0, self.max_nb_mismatches)\n",
    "        # create a dictionnary of nodes: width first\n",
    "        self.Nodes = {'0': [root]}\n",
    "        for d in range(1,self.maxdepth+1):\n",
    "            self.Nodes[str(d)] = []\n",
    "        count=0\n",
    "        while count<self.maxdepth:\n",
    "            for parent_ in self.Nodes[str(count)]:\n",
    "                for charact in alphabet:\n",
    "                    child = Node(parent_,charact)\n",
    "                    child.set_pointers(self.dataset, count, self.max_nb_mismatches)\n",
    "                    self.Nodes[str(count+1)].append(child)\n",
    "            count+=1                \n",
    "            \n",
    "    def get_Nodes(self):\n",
    "        return self.Nodes\n",
    "    \n",
    "    def build_kernel(self):\n",
    "        nb_substrings_per_string = 101-self.maxdepth+1\n",
    "        samples = self.dataset.reshape(-1,nb_substrings_per_string)\n",
    "        K = np.zeros((samples.shape[0], samples.shape[0]))\n",
    "        for leaf in self.Nodes[str(self.maxdepth)]:\n",
    "            one_hot = np.zeros(len(self.dataset))\n",
    "            one_hot[list(leaf.get_pointers().keys())]=1\n",
    "            occurences = one_hot.reshape(-1,nb_substrings_per_string).sum(axis=1)\n",
    "            print(occurences)\n",
    "            K = K + occurences.T@occurences\n",
    "        return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mismatch_kernel(X1, X2, k, m):\n",
    "    \"\"\"inputs:\n",
    "    - X1 (size N1xd): a set of strings\n",
    "    - X2 (size N2xd): another one\n",
    "    - k (integer): the length of the substrings considered\n",
    "    - m (integer): the order of mismatch accepted\n",
    "    ouput:\n",
    "    - the associated (N1+N2)x(N1+N2) mismatch kernel\n",
    "    \"\"\"\n",
    "    aggregated_data = np.hstack((X1,X2))\n",
    "    dataset_k = np.array([spectrum(x,k) for x in aggregated_data])\n",
    "    dataset_k = dataset_k.reshape(-1)\n",
    "    Test_tree = Tree(k=k, m=m, dataset=dataset_k)\n",
    "    kernel = Test_tree.build_kernel()\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "m = 1\n",
    "Nb_samples = 2000\n",
    "prop_test = 0.1\n",
    "\n",
    "X = pd.read_csv(f'{data_folder}/Xtr0.csv', sep = ',').to_numpy()[:,1]\n",
    "y = pd.read_csv(f'{data_folder}/ytr0.csv', sep = ',').to_numpy()[:,1]\n",
    "\n",
    "tr_indices = np.random.choice(Nb_samples, size=int((1-prop_test)*Nb_samples), replace=False)\n",
    "te_indices = [idx for idx in range(Nb_samples) if idx not in tr_indices]\n",
    "\n",
    "X_tr = X[tr_indices]\n",
    "X_te = X[te_indices]\n",
    "\n",
    "y_tr = y[tr_indices]\n",
    "y_te = y[te_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_m = Mismatch_kernel(X_tr,X_te,k,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.  5.]\n",
      "[ 6. 11.]\n",
      "[8. 4.]\n",
      "[9. 3.]\n",
      "[7. 4.]\n",
      "[5. 9.]\n",
      "[3. 4.]\n",
      "[3. 8.]\n",
      "[11.  7.]\n",
      "[6. 4.]\n",
      "[5. 4.]\n",
      "[5. 4.]\n",
      "[13.  7.]\n",
      "[9. 8.]\n",
      "[5. 2.]\n",
      "[7. 5.]\n",
      "[6. 8.]\n",
      "[ 3. 12.]\n",
      "[7. 5.]\n",
      "[5. 6.]\n",
      "[5. 8.]\n",
      "[ 3. 14.]\n",
      "[3. 6.]\n",
      "[1. 4.]\n",
      "[3. 3.]\n",
      "[ 7. 11.]\n",
      "[3. 1.]\n",
      "[4. 2.]\n",
      "[10.  7.]\n",
      "[6. 9.]\n",
      "[1. 5.]\n",
      "[1. 9.]\n",
      "[11.  4.]\n",
      "[2. 7.]\n",
      "[8. 6.]\n",
      "[3. 3.]\n",
      "[10.  6.]\n",
      "[5. 9.]\n",
      "[2. 4.]\n",
      "[5. 4.]\n",
      "[6. 1.]\n",
      "[5. 7.]\n",
      "[5. 1.]\n",
      "[4. 0.]\n",
      "[10.  5.]\n",
      "[8. 7.]\n",
      "[4. 1.]\n",
      "[5. 3.]\n",
      "[13.  7.]\n",
      "[9. 5.]\n",
      "[8. 4.]\n",
      "[9. 4.]\n",
      "[7. 7.]\n",
      "[4. 7.]\n",
      "[11.  2.]\n",
      "[3. 3.]\n",
      "[4. 2.]\n",
      "[5. 5.]\n",
      "[4. 0.]\n",
      "[2. 1.]\n",
      "[11.  7.]\n",
      "[ 5. 10.]\n",
      "[6. 4.]\n",
      "[3. 6.]\n",
      "[ 8. 12.]\n",
      "[4. 4.]\n",
      "[6. 5.]\n",
      "[6. 8.]\n",
      "[ 3. 11.]\n",
      "[ 2. 15.]\n",
      "[3. 8.]\n",
      "[7. 8.]\n",
      "[5. 6.]\n",
      "[5. 8.]\n",
      "[5. 3.]\n",
      "[6. 6.]\n",
      "[6. 6.]\n",
      "[6. 6.]\n",
      "[2. 3.]\n",
      "[ 9. 11.]\n",
      "[3. 7.]\n",
      "[ 3. 15.]\n",
      "[3. 8.]\n",
      "[7. 7.]\n",
      "[ 2. 15.]\n",
      "[ 4. 14.]\n",
      "[6. 8.]\n",
      "[ 3. 17.]\n",
      "[3. 5.]\n",
      "[ 6. 12.]\n",
      "[5. 4.]\n",
      "[5. 5.]\n",
      "[5. 7.]\n",
      "[ 5. 14.]\n",
      "[2. 5.]\n",
      "[2. 8.]\n",
      "[3. 5.]\n",
      "[3. 7.]\n",
      "[2. 2.]\n",
      "[8. 2.]\n",
      "[6. 8.]\n",
      "[ 5. 11.]\n",
      "[10.  7.]\n",
      "[5. 8.]\n",
      "[3. 3.]\n",
      "[7. 3.]\n",
      "[4. 1.]\n",
      "[7. 2.]\n",
      "[7. 3.]\n",
      "[6. 5.]\n",
      "[4. 2.]\n",
      "[4. 5.]\n",
      "[5. 5.]\n",
      "[2. 7.]\n",
      "[9. 4.]\n",
      "[6. 7.]\n",
      "[ 5. 10.]\n",
      "[ 7. 12.]\n",
      "[4. 7.]\n",
      "[6. 6.]\n",
      "[0. 6.]\n",
      "[1. 2.]\n",
      "[6. 0.]\n",
      "[2. 3.]\n",
      "[ 4. 10.]\n",
      "[3. 6.]\n",
      "[3. 2.]\n",
      "[2. 8.]\n",
      "[8. 1.]\n",
      "[2. 4.]\n",
      "[6. 4.]\n",
      "[7. 4.]\n",
      "[5. 8.]\n",
      "[1. 4.]\n",
      "[1. 2.]\n",
      "[3. 6.]\n",
      "[3. 4.]\n",
      "[5. 5.]\n",
      "[2. 0.]\n",
      "[6. 2.]\n",
      "[8. 2.]\n",
      "[6. 1.]\n",
      "[1. 0.]\n",
      "[4. 6.]\n",
      "[10.  7.]\n",
      "[4. 6.]\n",
      "[2. 3.]\n",
      "[7. 5.]\n",
      "[5. 4.]\n",
      "[ 3. 14.]\n",
      "[6. 6.]\n",
      "[4. 7.]\n",
      "[3. 4.]\n",
      "[7. 5.]\n",
      "[5. 2.]\n",
      "[5. 5.]\n",
      "[5. 4.]\n",
      "[5. 8.]\n",
      "[3. 0.]\n",
      "[5. 4.]\n",
      "[5. 2.]\n",
      "[4. 3.]\n",
      "[3. 0.]\n",
      "[6. 0.]\n",
      "[5. 3.]\n",
      "[5. 4.]\n",
      "[4. 2.]\n",
      "[5. 4.]\n",
      "[6. 0.]\n",
      "[4. 2.]\n",
      "[5. 0.]\n",
      "[4. 0.]\n",
      "[9. 0.]\n",
      "[4. 1.]\n",
      "[2. 0.]\n",
      "[3. 1.]\n",
      "[7. 3.]\n",
      "[5. 3.]\n",
      "[10.  1.]\n",
      "[7. 2.]\n",
      "[8. 6.]\n",
      "[4. 2.]\n",
      "[5. 1.]\n",
      "[4. 5.]\n",
      "[4. 0.]\n",
      "[1. 3.]\n",
      "[2. 0.]\n",
      "[3. 0.]\n",
      "[7. 4.]\n",
      "[4. 4.]\n",
      "[2. 1.]\n",
      "[2. 3.]\n",
      "[7. 5.]\n",
      "[7. 6.]\n",
      "[6. 6.]\n",
      "[12.  7.]\n",
      "[5. 7.]\n",
      "[4. 4.]\n",
      "[6. 3.]\n",
      "[4. 8.]\n",
      "[6. 3.]\n",
      "[10.  6.]\n",
      "[8. 2.]\n",
      "[11.  4.]\n",
      "[12.  5.]\n",
      "[5. 5.]\n",
      "[6. 3.]\n",
      "[5. 5.]\n",
      "[5. 6.]\n",
      "[ 5. 10.]\n",
      "[9. 7.]\n",
      "[4. 8.]\n",
      "[4. 6.]\n",
      "[ 5. 12.]\n",
      "[3. 5.]\n",
      "[6. 5.]\n",
      "[7. 3.]\n",
      "[7. 7.]\n",
      "[8. 2.]\n",
      "[7. 3.]\n",
      "[2. 5.]\n",
      "[6. 8.]\n",
      "[3. 2.]\n",
      "[4. 6.]\n",
      "[4. 2.]\n",
      "[1. 3.]\n",
      "[3. 3.]\n",
      "[2. 4.]\n",
      "[2. 3.]\n",
      "[3. 7.]\n",
      "[3. 3.]\n",
      "[3. 0.]\n",
      "[3. 1.]\n",
      "[4. 1.]\n",
      "[5. 0.]\n",
      "[3. 0.]\n",
      "[3. 1.]\n",
      "[3. 2.]\n",
      "[0. 0.]\n",
      "[3. 3.]\n",
      "[7. 9.]\n",
      "[3. 7.]\n",
      "[8. 6.]\n",
      "[6. 5.]\n",
      "[3. 7.]\n",
      "[3. 7.]\n",
      "[8. 5.]\n",
      "[2. 7.]\n",
      "[2. 4.]\n",
      "[5. 3.]\n",
      "[3. 2.]\n",
      "[2. 2.]\n",
      "[2. 6.]\n",
      "[4. 7.]\n",
      "[1. 4.]\n",
      "[2. 8.]\n"
     ]
    }
   ],
   "source": [
    "X_tr = X_tr[:1]\n",
    "X_te = X_te[:1]\n",
    "\n",
    "K_m = Mismatch_kernel(X_tr,X_te,k,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.9075945852892406e-06\n"
     ]
    }
   ],
   "source": [
    "print(np.amin(np.linalg.eig(K_m)[0].real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_m = K_m + np.eye(K_m.shape[0])*pow(10,-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_train = K_m[:1800,:1800]\n",
    "K_pred = K_m[:1800,1800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_tr = K_train.shape[0]\n",
    "lamb = 1\n",
    "# Define QP and solve it with cvxpy\n",
    "alpha = cp.Variable(N_tr)\n",
    "objective = cp.Maximize(2*alpha.T@y_tr - cp.quad_form(alpha, K_train))\n",
    "constraints = [0 <= cp.multiply(y_tr,alpha), cp.multiply(y_tr,alpha) <= 1/(2*lamb*N_tr)]\n",
    "prob = cp.Problem(objective, constraints)\n",
    "# The optimal objective value is returned by `prob.solve()`.\n",
    "result = prob.solve()\n",
    "# The optimal value for x is stored in `x.value`.\n",
    "alpha_ = alpha.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_te = 2 * (alpha_.T@K_pred > 0).reshape(-1, ).astype(\"int\") - 1\n",
    "y_pred_tr = 2 * (alpha_.T@K_train > 0).reshape(-1, ).astype(\"int\") - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4777777777777778\n",
      "0.51\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(y_pred_tr == y_tr)/y_tr.shape[0])\n",
    "print(np.sum(y_pred_te == y_te)/y_te.shape[0])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "KM_challenge_new.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
