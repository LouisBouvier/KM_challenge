{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Pz797qSo1Wd9"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/MVA/KKML'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9082c1155c9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/MVA/KKML'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/MVA/KKML'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/MyDrive/MVA/KKML')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqUQTmZ20az9"
   },
   "source": [
    "# Kernel Methods: Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAISFXMk0a0D"
   },
   "source": [
    "Julia Linhart, Roman Castagné, Louis Bouvier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXbC5eRC0a0D"
   },
   "source": [
    "Preliminary functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZvAm-YyB0a0E"
   },
   "outputs": [],
   "source": [
    "def write_csv(ids, labels, filename):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        - ids: list of ids, should be an increasing list of integers\n",
    "        - labels: list of corresponding labels, either 0 or 1\n",
    "        - file: string containing the name that should be given to the submission file    \n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\"Id\": ids, \"Bound\": labels})\n",
    "    df[\"Bound\"] = df[\"Bound\"].replace([-1], 0)\n",
    "    df.to_csv(filename, sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiFKdzlB0a0E"
   },
   "source": [
    "# I) Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZKNsQc940a0F"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import cvxpy as cp\n",
    "import warnings\n",
    "import time\n",
    "from itertools import product\n",
    "from numba import jit\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XrXWzksi0a0F"
   },
   "outputs": [],
   "source": [
    "data_folder = 'data' # 'machine-learning-with-kernel-methods-2021'\n",
    "\n",
    "X_train_1 = pd.read_csv(f'{data_folder}/Xtr2_mat100.csv', sep = ' ', index_col=False, header=None)\n",
    "y_train_1 = pd.read_csv(f'{data_folder}/Ytr2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "8SY4m9HA0a0F",
    "outputId": "bb2b1fd8-36f1-4ec4-97ee-40dc6aeac607"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4999.500000</td>\n",
       "      <td>0.498500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>577.494589</td>\n",
       "      <td>0.500123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4499.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4999.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5499.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id        Bound\n",
       "count  2000.000000  2000.000000\n",
       "mean   4999.500000     0.498500\n",
       "std     577.494589     0.500123\n",
       "min    4000.000000     0.000000\n",
       "25%    4499.750000     0.000000\n",
       "50%    4999.500000     0.000000\n",
       "75%    5499.250000     1.000000\n",
       "max    5999.000000     1.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "JcoPE7dE0a0H"
   },
   "outputs": [],
   "source": [
    "y_train_1 = np.array(y_train_1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "bgo-XP0u0a0I",
    "outputId": "4fa3e853-5782-4b65-a4a0-eb8906fd7df5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.010565</td>\n",
       "      <td>0.010201</td>\n",
       "      <td>0.010375</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.011609</td>\n",
       "      <td>0.010707</td>\n",
       "      <td>0.009359</td>\n",
       "      <td>0.011957</td>\n",
       "      <td>0.009571</td>\n",
       "      <td>0.010582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007951</td>\n",
       "      <td>0.009457</td>\n",
       "      <td>0.008554</td>\n",
       "      <td>0.009283</td>\n",
       "      <td>0.008261</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>0.011141</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>0.008217</td>\n",
       "      <td>0.008565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012278</td>\n",
       "      <td>0.010723</td>\n",
       "      <td>0.011467</td>\n",
       "      <td>0.011453</td>\n",
       "      <td>0.012182</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>0.009789</td>\n",
       "      <td>0.012444</td>\n",
       "      <td>0.013805</td>\n",
       "      <td>0.013652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009605</td>\n",
       "      <td>0.009701</td>\n",
       "      <td>0.009350</td>\n",
       "      <td>0.009741</td>\n",
       "      <td>0.012341</td>\n",
       "      <td>0.010338</td>\n",
       "      <td>0.010863</td>\n",
       "      <td>0.010402</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.009283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.097826</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.097826</td>\n",
       "      <td>0.184783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean      0.010565     0.010201     0.010375     0.011587     0.011609   \n",
       "std       0.012278     0.010723     0.011467     0.011453     0.012182   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.010870     0.010870     0.010870     0.010870     0.010870   \n",
       "75%       0.010870     0.021739     0.021739     0.021739     0.021739   \n",
       "max       0.086957     0.065217     0.097826     0.065217     0.065217   \n",
       "\n",
       "                5            6            7            8            9   ...  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000  ...   \n",
       "mean      0.010707     0.009359     0.011957     0.009571     0.010582  ...   \n",
       "std       0.010478     0.009789     0.012444     0.013805     0.013652  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.010870     0.010870     0.010870     0.000000     0.010870  ...   \n",
       "75%       0.021739     0.010870     0.021739     0.010870     0.021739  ...   \n",
       "max       0.054348     0.054348     0.076087     0.097826     0.184783  ...   \n",
       "\n",
       "                90           91           92           93           94  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean      0.007951     0.009457     0.008554     0.009283     0.008261   \n",
       "std       0.009605     0.009701     0.009350     0.009741     0.012341   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.010870     0.010870     0.010870     0.010870     0.000000   \n",
       "75%       0.010870     0.010870     0.010870     0.010870     0.010870   \n",
       "max       0.054348     0.065217     0.054348     0.054348     0.086957   \n",
       "\n",
       "                95           96           97           98           99  \n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000  \n",
       "mean      0.009614     0.011141     0.009777     0.008217     0.008565  \n",
       "std       0.010338     0.010863     0.010402     0.009709     0.009283  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.010870     0.010870     0.010870     0.010870     0.010870  \n",
       "75%       0.010870     0.021739     0.010870     0.010870     0.010870  \n",
       "max       0.065217     0.076087     0.065217     0.065217     0.043478  \n",
       "\n",
       "[8 rows x 100 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZJU9wcKY0a0I",
    "outputId": "0f85cc84-d6c1-4259-a9fd-8eae7acdf52e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 100)\n"
     ]
    }
   ],
   "source": [
    "X_train_1 = np.array(X_train_1)\n",
    "print(X_train_1.shape)\n",
    "X_train_1 = (X_train_1 - X_train_1.mean(axis=0))/X_train_1.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8G8Z3xuG0a0J",
    "outputId": "cb0bb08c-a8d5-4eda-f723-847c647f955b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJFmTps10a0J"
   },
   "source": [
    "# II) First linear models of the mat100 input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovYDI_gw0a0J"
   },
   "source": [
    "## A) Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "_E7S-54J0a0K"
   },
   "outputs": [],
   "source": [
    "def g(z):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    - z (any size): an array-like element\n",
    "    ouput:\n",
    "    - the element-wize application of the sigmoïd function on z\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ktw_MldY0a0K"
   },
   "outputs": [],
   "source": [
    "def compute_loss(X,y,w,b):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    - X (size: Nxd): the points we want to classify\n",
    "    - y (size: Nx1): the values of the classes\n",
    "    - w (size: 1xd): the weights of the affine mapping of x\n",
    "    - b (size: 1x1): the constant of the affine mapping of x\n",
    "    output:\n",
    "    - the opposite of the log-likelihood of the Logistic Regression model computed with respect to\n",
    "    the points (X,y) and the parameters w,b\n",
    "    \"\"\"\n",
    "    X_tilde = np.hstack([X, np.ones((X.shape[0], 1))])\n",
    "    w_tilde = np.hstack((w,b))\n",
    "    return -np.sum(y * np.log(g(w_tilde@X_tilde.T)) + (1-y) * np.log(1-g(w_tilde@X_tilde.T)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ohAlip1w0a0K"
   },
   "outputs": [],
   "source": [
    "def compute_grad(X,y,w,b):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    - X (size: Nxd): the points we want to classify\n",
    "    - y (size: Nx1): the values of the classes\n",
    "    - w (size: 1xd): the weights of the affine mapping of x\n",
    "    - b (size: 1x1): the constant of the affine mapping of x\n",
    "    output:\n",
    "    - the gradient of the loss of the Logistic Regression model computed \n",
    "    with respect to (w,b) = w_tilde having the points (X,y) \n",
    "    \"\"\"\n",
    "    X_tilde = np.hstack([X, np.ones((X.shape[0], 1))])\n",
    "    w_tilde = np.hstack((w,b))\n",
    "    return -X_tilde.T @ (y - g(w_tilde@X_tilde.T).reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "PhijbHZk0a0L"
   },
   "outputs": [],
   "source": [
    "def compute_hess(X,y,w,b):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    - X (size: Nxd): the points we want to classify\n",
    "    - y (size: Nx1): the values of the classes\n",
    "    - w (size: 1xd): the weights of the affine mapping of x\n",
    "    - b (size: 1x1): the constant of the affine mapping of x\n",
    "    output:\n",
    "    - the hessian of the loss of the Logistic Regression model computed \n",
    "    with respect to (w,b) = w_tilde having the points (X,y) \n",
    "    \"\"\"\n",
    "    X_tilde = np.hstack([X, np.ones((X.shape[0], 1))])\n",
    "    w_tilde = np.hstack((w,b))    \n",
    "    temp = (g(w_tilde @ X_tilde.T) * (g(w_tilde @ X_tilde.T) - 1)).reshape(-1,)\n",
    "    return -X_tilde.T @ np.diag(temp) @ X_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "CB6KETwa0a0L"
   },
   "outputs": [],
   "source": [
    "def backtracking(X,y,w,b,delta,grad,alpha=0.1,beta=0.7):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    - X (size: Nxd): the points we want to classify\n",
    "    - y (size: Nx1): the values of the classes\n",
    "    - w (size: 1xd): the weights of the affine mapping of x\n",
    "    - b (size: 1x1): the constant of the affine mapping of x\n",
    "    - delta (size n): direction of the search\n",
    "    - grad (size n): value of the gradient at point (w,b)\n",
    "    - alpha: factor of the slope of the line in the backtracking line search\n",
    "    - beta: factor of reduction of the step length\n",
    "    \n",
    "    outputs:\n",
    "    - t: the step length for the Newton step on the objective function\n",
    "    computed with backtracking line search towards delta\"\"\"\n",
    "        \n",
    "    t = 1\n",
    "    while(compute_loss(X, y, w+t*delta[:-1], b+t*delta[-1])>\n",
    "            compute_loss(X,y,w,b) + alpha*t*grad.T @ delta):\n",
    "        t = beta*t\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "c-jkPwuu0a0M"
   },
   "outputs": [],
   "source": [
    "def Newton(X, y, w0, b0, eps=pow(10,-1)):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    - X (size: Nxd): the points we want to classify\n",
    "    - y (size: Nx1): the values of the classes\n",
    "    - w0 (size: 1xd): the initial weights of the affine mapping of x\n",
    "    - b0 (size: 1x1): the initial constant of the affine mapping of x\n",
    "    output:\n",
    "    - the paramer vector w_tilde_hat = (w_hat, b_hat) which maximizes the log-likelihood of \n",
    "    the sample (X,y) in the Logistic Regression model (or minimizes the loss)\n",
    "    - the cached values of the loss evaluated along training\n",
    "    \"\"\"\n",
    "    w_, b_ = w0, b0\n",
    "    grad = compute_grad(X, y, w0, b0)\n",
    "    hess = compute_hess(X, y, w0, b0)\n",
    "    \n",
    "#     inv_hess = np.linalg.inv(compute_hess(X,y,w0,b0))\n",
    "    inv_hess, _, _, _ = np.linalg.lstsq(hess, np.eye(hess.shape[0]))\n",
    "    dec_2 = grad.T@inv_hess@grad\n",
    "    Loss_hist = [compute_loss(X,y,w0,b0)]\n",
    "    while dec_2/2 > eps: # condition on the Newton decrement\n",
    "        grad = compute_grad(X,y,w_,b_)\n",
    "        hess = compute_hess(X,y,w_,b_)\n",
    "        \n",
    "#         inv_hess = np.linalg.inv(compute_hess(X,y,w_,b_))\n",
    "        inv_hess, _, _, _ = np.linalg.lstsq(hess, np.eye(hess.shape[0]))\n",
    "        dec_2 = grad.T@inv_hess@grad\n",
    "        delta = - inv_hess@grad\n",
    "        t_bt = backtracking(X, y, w_, b_, delta, grad)\n",
    "        w_ = w_ + t_bt*delta[:-1]\n",
    "        b_ = b_ + t_bt*delta[-1]\n",
    "        Loss_hist.append(compute_loss(X,y,w_,b_))\n",
    "    return w_, b_, Loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "V_kXI2MU0a0M"
   },
   "outputs": [],
   "source": [
    "def predict_LogReg(x,w,b):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    - x (size 1xd): a point in R^d\n",
    "    - w (size: 1xd): the weights of the affine mapping of x\n",
    "    - b (size: 1x1): the constant of the affine mapping of x\n",
    "    output:\n",
    "     - the predicted class for the associated y given the\n",
    "    Logistic Regression parameters\n",
    "    \"\"\"    \n",
    "    return (w.T@x + b > 0).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "DG8epkzE0a0N"
   },
   "outputs": [],
   "source": [
    "class LogisticRegressor(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, lamb=1.):\n",
    "        \"\"\"\n",
    "        This class implements methods for fitting and predicting with a LogesticRegression for classification \n",
    "        inputs:\n",
    "        - lamb : the regularisation parameter\n",
    "        \"\"\"\n",
    "        self.lamb = lamb\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "        - X (size: Nxd): the points we want to classify\n",
    "        - y (size: Nx1): the values of the classes\n",
    "        outputs:\n",
    "        - the value of MLE estimation (w_hat, b_hat) in the Linear regression model\n",
    "        \"\"\"\n",
    "        w0, b0 = np.random.randn(1, 100)*0.07, np.zeros((1,1))\n",
    "        self.w_, self.b_, _ = Newton(X, y, w0, b0)\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "        - X (size Nxd): a point in R^d\n",
    "        - w (size: 1xd): the weights of the affine mapping of x\n",
    "        - b (size: 1x1): the constant of the affine mapping of x\n",
    "        output:\n",
    "         - the predicted class for the associated y given the\n",
    "        Linear Regression parameters\n",
    "        \"\"\"    \n",
    "        return (self.w_@X.T + self.b_ > 1/2).astype(\"int\")\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "        - X (size Nxd): the points in R^d we want to classify\n",
    "        - y (size Nx1): the labels of the points\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        return np.sum(y_pred == y)/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xuYAhP_70a0O",
    "outputId": "9799757c-a1f0-46b3-cb40-9a623ca6c35f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louisbouvier/Documents/MVA-MPRO/MVA/S2/Learning/Kernel Methods/challenge/KM_env/lib/python3.7/site-packages/ipykernel_launcher.py:18: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "/Users/louisbouvier/Documents/MVA-MPRO/MVA/S2/Learning/Kernel Methods/challenge/KM_env/lib/python3.7/site-packages/ipykernel_launcher.py:26: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set 0: 0.62\n",
      "Accuracy on test set 0 : 0.56\n",
      "Accuracy on train set 1: 0.60\n",
      "Accuracy on test set 1 : 0.59\n",
      "Accuracy on train set 2: 0.70\n",
      "Accuracy on test set 2 : 0.66\n"
     ]
    }
   ],
   "source": [
    "dim = 100\n",
    "Nb_samples = 2000\n",
    "prop_test = 0.05\n",
    "\n",
    "all_y_eval = []\n",
    "\n",
    "np.random.seed(1)\n",
    "for name in [0, 1, 2]:\n",
    "    X = pd.read_csv(f'{data_folder}/Xtr{name}_mat100.csv', sep = ' ', index_col=False, header=None).to_numpy()\n",
    "    y = pd.read_csv(f'{data_folder}/Ytr{name}.csv')\n",
    "    y = y[\"Bound\"].to_numpy()\n",
    "    \n",
    "    mean, std = X.mean(axis=0), X.std(axis=0)\n",
    "    X = (X - mean)/std\n",
    "\n",
    "    tr_indices = np.random.choice(Nb_samples, size=int((1-prop_test)*Nb_samples), replace=False)\n",
    "    te_indices = [idx for idx in range(Nb_samples) if idx not in tr_indices]\n",
    "\n",
    "    X_tr = X[tr_indices]\n",
    "    X_te = X[te_indices]\n",
    "    \n",
    "    y_tr = y[tr_indices]\n",
    "    y_te = y[te_indices]\n",
    "    \n",
    "    assert X_tr.shape[0] + X_te.shape[0] == X.shape[0]\n",
    "    assert y_tr.shape[0] + y_te.shape[0] == y.shape[0]\n",
    "    \n",
    "    # Fitting\n",
    "    logreg = LogisticRegressor()\n",
    "    \n",
    "    logreg.fit(X_tr, y_tr)\n",
    "\n",
    "    \n",
    "    print(f\"Accuracy on train set {name}: {logreg.score(X_tr, y_tr):.2f}\")\n",
    "    print(f\"Accuracy on test set {name} : {logreg.score(X_te, y_te):.2f}\")   \n",
    "    \n",
    "    # Prediction on the new set\n",
    "    X_eval = pd.read_csv(f'{data_folder}/Xte{name}_mat100.csv', sep = ' ', index_col=False, header=None).to_numpy()\n",
    "    X_eval = (X_eval - mean)/std\n",
    "    y_eval = logreg.predict(X_eval)\n",
    "    all_y_eval.append(y_eval)\n",
    "    \n",
    "all_y_eval = np.hstack(all_y_eval).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "N-_1EYnY0a0O",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ids = np.arange(all_y_eval.shape[0])\n",
    "filename = \"results/submission_log_reg.csv\"\n",
    "\n",
    "# write_csv(ids, all_y_eval, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LPAM0yW0a0P"
   },
   "source": [
    "## B) Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "wZYbRtxE0a0Q"
   },
   "outputs": [],
   "source": [
    "def compute_RR_MLE(X,y,lamb):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    - X (size: Nxd): the points we want to classify\n",
    "    - y (size: Nx1): the values of the classes\n",
    "    outputs:\n",
    "    - the value of MLE estimation (w_hat, b_hat) in the Linear regression model\n",
    "    \"\"\"\n",
    "    X_tilde = np.vstack((X,np.ones(X.shape[1])))\n",
    "    temp = np.linalg.inv(X_tilde@X_tilde.T + lamb*X.shape[1]*np.eye(1+X.shape[0]))@X_tilde@y.T\n",
    "    return temp[:-1], temp[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "d3923wu80a0Q"
   },
   "outputs": [],
   "source": [
    "def predict_RR(x,w,b):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    - x (size 1xd): a point in R^d\n",
    "    - w (size: 1xd): the weights of the affine mapping of x\n",
    "    - b (size: 1x1): the constant of the affine mapping of x\n",
    "    output:\n",
    "     - the predicted class for the associated y given the\n",
    "    Linear Regression parameters\n",
    "    \"\"\"    \n",
    "    return (w.T@x+b>1/2).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "wux5BgTY0a0Q"
   },
   "outputs": [],
   "source": [
    "class RidgeRegressor(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, lamb=1.):\n",
    "        \"\"\"\n",
    "        This class implements methods for fitting and predicting with a RidgeRegressor used for classification \n",
    "        (by thresholding the value regressed).\n",
    "        inputs:\n",
    "        - lamb : the regularisation parameter\n",
    "        \"\"\"\n",
    "        self.lamb = lamb\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "        - X (size: Nxd): the points we want to classify\n",
    "        - y (size: Nx1): the values of the classes\n",
    "        outputs:\n",
    "        - the value of MLE estimation (w_hat, b_hat) in the Linear regression model\n",
    "        \"\"\"\n",
    "        X_tilde = np.hstack((X, np.ones((X.shape[0], 1))))\n",
    "        temp = np.linalg.inv(X_tilde.T @ X_tilde + self.lamb * X.shape[0] * np.eye(X_tilde.shape[1])) @ (X_tilde.T @ y)\n",
    "        self.w_ = temp[:-1]\n",
    "        self.b_ = temp[-1]\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "        - x (size Nxd): a point in R^d\n",
    "        - w (size: 1xd): the weights of the affine mapping of x\n",
    "        - b (size: 1x1): the constant of the affine mapping of x\n",
    "        output:\n",
    "         - the predicted class for the associated y given the\n",
    "        Linear Regression parameters\n",
    "        \"\"\"    \n",
    "        return (self.w_@X.T + self.b_ > 1/2).astype(\"int\")\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "        - X (size Nxd): the points in R^d we want to classify\n",
    "        - y (size Nx1): the labels of the points\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        return np.sum(y_pred == y)/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zK4wdATY0a0Q",
    "outputId": "93c497fb-859c-4d42-828c-dccdf6907f6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lamb': 0.021842105263157895}\n",
      "Accuracy on train set 0: 0.65\n",
      "Accuracy on test set 0 : 0.60\n",
      "{'lamb': 0.001}\n",
      "Accuracy on train set 1: 0.64\n",
      "Accuracy on test set 1 : 0.57\n",
      "{'lamb': 0.04268421052631579}\n",
      "Accuracy on train set 2: 0.73\n",
      "Accuracy on test set 2 : 0.69\n"
     ]
    }
   ],
   "source": [
    "dim = 100\n",
    "Nb_samples = 2000\n",
    "prop_test = 0.05\n",
    "lamb = 0.1\n",
    "\n",
    "all_y_eval = []\n",
    "\n",
    "np.random.seed(1)\n",
    "for name in [0, 1, 2]:\n",
    "    # Data processing\n",
    "    X = pd.read_csv(f'{data_folder}/Xtr{name}_mat100.csv', sep = ' ', index_col=False, header=None).to_numpy()\n",
    "    y = pd.read_csv(f'{data_folder}/Ytr{name}.csv')\n",
    "    y = y[\"Bound\"].to_numpy()\n",
    "    \n",
    "    mean, std = X.mean(axis=0), X.std(axis=0)\n",
    "    X = (X - mean)/std\n",
    "\n",
    "    tr_indices = np.random.choice(Nb_samples, size=int((1-prop_test)*Nb_samples), replace=False)\n",
    "    te_indices = [idx for idx in range(Nb_samples) if idx not in tr_indices]\n",
    "\n",
    "    X_tr = X[tr_indices]\n",
    "    X_te = X[te_indices]\n",
    "    \n",
    "    y_tr = y[tr_indices]\n",
    "    y_te = y[te_indices]\n",
    "    \n",
    "    assert X_tr.shape[0] + X_te.shape[0] == X.shape[0]\n",
    "    assert y_tr.shape[0] + y_te.shape[0] == y.shape[0]\n",
    "    \n",
    "    # Fitting the classifier\n",
    "    params = {'lamb': np.linspace(0.001, 0.1, 20)}\n",
    "    rr = GridSearchCV(RidgeRegressor(), params)\n",
    "#     rr = RidgeRegressor(lamb=lamb)\n",
    "\n",
    "    rr.fit(X_tr, y_tr)\n",
    "    \n",
    "    print(rr.best_params_)\n",
    "    \n",
    "    print(f\"Accuracy on train set {name}: {rr.score(X_tr, y_tr):.2f}\")\n",
    "    print(f\"Accuracy on test set {name} : {rr.score(X_te, y_te):.2f}\")\n",
    "    \n",
    "    # Prediction on the new set\n",
    "    X_eval = pd.read_csv(f'{data_folder}/Xte{name}_mat100.csv', sep = ' ', index_col=False, header=None).to_numpy()\n",
    "    X_eval = (X_eval - mean)/std\n",
    "    y_eval = rr.predict(X_eval)\n",
    "    all_y_eval.append(y_eval)\n",
    "    \n",
    "all_y_eval = np.hstack(all_y_eval).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtjBOLml0a0R"
   },
   "source": [
    "# III) Kernel baselines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Ie35LaC0a0R"
   },
   "source": [
    "## A) Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "1eOe1mTP0a0R"
   },
   "outputs": [],
   "source": [
    "def Gaussian_kernel(X1, X2, sig):\n",
    "    \"\"\"inputs:\n",
    "    - X1 (size N1xd): a set of points\n",
    "    - X2 (size N2xd): another one  \n",
    "    - sig (float): the std of the kernel\n",
    "    ouput:\n",
    "    - the associated (N1xN2) Gaussian kernel\n",
    "    \"\"\"\n",
    "    return np.exp(-distance_matrix(X1,X2)/(2*sig**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Spectrum kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "9rKFOspuz7IS"
   },
   "outputs": [],
   "source": [
    "def spectrum(x,k):\n",
    "    l = len(x)\n",
    "    spectrum_x = np.array([x[i:(i + k)] for i in range(l - k + 1)])\n",
    "    return np.array(spectrum_x)\n",
    "\n",
    "def Spectrum_kernel(X1, X2, k):\n",
    "    \"\"\"inputs:\n",
    "    - X1 (size N1xd): a set of sequences\n",
    "    - X2 (size N2xd): another one  \n",
    "    - k (int): the length of the substrings \n",
    "    ouput:\n",
    "    - the associated (N1xN2) Spectrum kernel\n",
    "    \"\"\"\n",
    "    # substrings: all possible combinations of A,T,G,C of length k\n",
    "    A_k = [''.join(s) for s in product([\"A\", \"T\", \"G\", \"C\"], repeat=k)]\n",
    "\n",
    "    # nb of occurances of the elements of A_k in the k-spectrum of X1 (resp. X2)\n",
    "    phi_spect_X1 = np.array([[np.sum(spectrum(x,k)==u) for u in A_k] for x in X1])\n",
    "    phi_spect_X2 = np.array([[np.sum(spectrum(x,k)==u) for u in A_k] for x in X2])\n",
    "    \n",
    "    K_s = phi_spect_X1 @ phi_spect_X2.T\n",
    "    K_s = K_s + np.eye(K_s.shape[0], K_s.shape[1])*pow(10,-12)\n",
    "    return K_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Substring kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def substring_similarity(seq_1, seq_2, k, lambd):\n",
    "    # Initialize K and B\n",
    "    K_temp = [np.ones((len(seq_1), len(seq_2)))]\n",
    "    K_temp += [np.zeros((len(seq_1), len(seq_2))) for _ in range(k)]\n",
    "\n",
    "    B_temp = [np.ones((len(seq_1), len(seq_2)))]\n",
    "    B_temp += [np.zeros((len(seq_1), len(seq_2))) for _ in range(k)]\n",
    "\n",
    "    for l in range(1, k+1):\n",
    "        # First, loop over the first sequence\n",
    "        for i_str_1 in range(len(seq_1)):\n",
    "\n",
    "            # Then, loop over the second sequence\n",
    "            for i_str_2 in range(len(seq_2)):\n",
    "                a = seq_1[i_str_1]\n",
    "                b = seq_2[i_str_2]\n",
    "                \n",
    "                # If min < l, then the matrix already has zeros in the right place : we can continue\n",
    "                if min(i_str_1, i_str_2) >= l-1:\n",
    "\n",
    "                    if i_str_1 == 0 and i_str_2 == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    if i_str_2 == 0:\n",
    "                        # Computation of B\n",
    "                        B_temp[l][i_str_1, i_str_2] = lambd * B_temp[l][i_str_1-1, i_str_2]\n",
    "                        K_temp[l][i_str_1, i_str_2] = K_temp[l][i_str_1-1, i_str_2]\n",
    "                        \n",
    "                    elif i_str_1 == 0:\n",
    "                        B_temp[l][i_str_1, i_str_2] = lambd * B_temp[l][i_str_1, i_str_2-1]\n",
    "                        K_temp[l][i_str_1, i_str_2] = K_temp[l][i_str_1, i_str_2-1]\n",
    "\n",
    "                    else:\n",
    "                        B_temp[l][i_str_1, i_str_2] = lambd * B_temp[l][i_str_1-1, i_str_2] \\\n",
    "                                                    + lambd * B_temp[l][i_str_1, i_str_2-1] \\\n",
    "                                                    - lambd ** 2 * B_temp[l][i_str_1-1, i_str_2-1] \\\n",
    "                                                    + lambd ** 2 * int(a == b) * B_temp[l-1][i_str_1-1, i_str_2-1]\n",
    "\n",
    "                        # This corresponds to the sum in the computation of K\n",
    "                        # !!!!! This one is probably wrong !!!!!\n",
    "#                         K_sum_1 = 0\n",
    "#                         for j_prime in range(i_str_2+1):\n",
    "#                             if seq_2[j_prime] == a:\n",
    "#                                 K_sum_1 += B_temp[l-1][i_str_1-1, j_prime-1]\n",
    "\n",
    "#                         # Computation of K\n",
    "#                         K_temp[l][i_str_1, i_str_2] = K_temp[l][i_str_1-1, i_str_2] + lambd ** 2 * K_sum_1\n",
    "\n",
    "                        # This one is wrong too, but less\n",
    "                        K_temp[l][i_str_1, i_str_2] = K_temp[l][i_str_1-1, i_str_2] \\\n",
    "                                                    + K_temp[l][i_str_1, i_str_2-1] \\\n",
    "                                                    - K_temp[l][i_str_1-1, i_str_2-1] \\\n",
    "                                                    + lambd ** 2 * int(a == b) * B_temp[l-1][i_str_1-1, i_str_2-1]\n",
    "\n",
    "    return K_temp[k][-1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substring_kernel(X1, X2, k, lambd):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    assert all([type(x) == str for x in X1]), \"not a list of strings\"\n",
    "    assert all([type(x) == str for x in X2]), \"not a list of strings\"\n",
    "    \n",
    "    K = - np.ones((len(X1), len(X2)))\n",
    "    \n",
    "    for i, seq_1 in enumerate(X1):\n",
    "        for j, seq_2 in enumerate(X2):\n",
    "            # This basically corresponds to filling the lower diagonal\n",
    "            if seq_2 in X1 and seq_1 in X2 and K[np.where(X1 == seq_2), np.where(X2 == seq_1)] != -1:\n",
    "                K[i, j] = K[np.where(X1 == seq_2), np.where(X2 == seq_1)]\n",
    "            else:\n",
    "                K[i, j] = substring_similarity(seq_1, seq_2, k, lambd)\n",
    "\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute : 1.7824s\n",
      "Value : 0.24009999999999992\n",
      "Expected value : 0.5978489999999999\n"
     ]
    }
   ],
   "source": [
    "# Run similarity between two strings\n",
    "t0 = time.time()\n",
    "# k = substring_similarity(\"ATGCATGATGCATG\", \"ATGCATCATGATGT\", 3, 1.)\n",
    "# k = substring_similarity(\"ATGC\", \"ATGC\", 3, 0.7)\n",
    "# k = substring_similarity(\"ATTTGCCGTATC\", \"AGGCTCTCCAGC\", 2, 0.7)\n",
    "k = substring_similarity(\"cat\", \"cat\", 2, 0.7)\n",
    "# k = substring_similarity(\"ACGT\", \"TGCG\", 2, 0.7)\n",
    "k_expected = 2 * (0.7 ** 4) + 0.7 ** 6\n",
    "print(f\"Time to compute : {time.time() - t0:.4f}s\")\n",
    "print(f\"Value : {k}\")\n",
    "print(f\"Expected value : {k_expected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute K : 0.68s\n"
     ]
    }
   ],
   "source": [
    "# Run kernel computation between N strings\n",
    "X = pd.read_csv(f'{data_folder}/Xtr0.csv', sep = ',').to_numpy()\n",
    "X = X[:10,1]\n",
    "t0 = time.time()\n",
    "K = substring_kernel(X, X, k=5, lambd=0.7)\n",
    "print(f\"Time to compute K : {time.time() - t0:.2f}s\")\n",
    "assert np.allclose(K, K.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed kernel for dataset 0 in 39224.60s.\n",
      "Computed evaluation kernel for dataset 0 in 91215.05s.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-179-880c45778a42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mX_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{data_folder}/Xtr{name}.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mX_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_tr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubstring_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlambd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Computed kernel for dataset {name} in {time.time() - t0:.2f}s.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{data_folder}/Ktrtr{name}_k={k}_lambda={lambd}.npy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-162-140780d5875c>\u001b[0m in \u001b[0;36msubstring_kernel\u001b[1;34m(X1, X2, k, lambd)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;31m# This basically corresponds to filling the lower diagonal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mseq_2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mseq_1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mseq_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mseq_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m                 \u001b[0mK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mseq_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mseq_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "lambd = 0.7\n",
    "\n",
    "for name in {0, 1, 2}:\n",
    "    t0 = time.time()\n",
    "    X_tr = pd.read_csv(f'{data_folder}/Xtr{name}.csv', sep = ',').to_numpy()\n",
    "    X_tr = X_tr[:,1]\n",
    "    K = substring_kernel(X_tr, X_tr, k=k, lambd=lambd)\n",
    "    print(f\"Computed kernel for dataset {name} in {time.time() - t0:.2f}s.\")\n",
    "    with open(f\"{data_folder}/Ktrtr{name}_k={k}_lambda={lambd}.npy\", \"wb\") as f:\n",
    "        np.save(f, K)\n",
    "    \n",
    "    \n",
    "    t0 = time.time()\n",
    "    X_ev = pd.read_csv(f'{data_folder}/Xte{name}.csv', sep = ',').to_numpy()\n",
    "    X_ev = X_ev[:, 1]\n",
    "    K = substring_kernel(X_tr, X_ev, k=k, lambd=lambd)\n",
    "    print(f\"Computed evaluation kernel for dataset {name} in {time.time() - t0:.2f}s.\")\n",
    "    with open(f\"{data_folder}/Ktreval{name}_k={k}_lambda={lambd}.npy\", \"wb\") as f:\n",
    "        np.save(f, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_precomputed_kernel(df_train, df_eval, kernel_filename_train, kernel_filename_eval, normalize=False):\n",
    "    with open(kernel_filename_train, \"rb\") as f:\n",
    "        K_tr = np.load(f)\n",
    "    with open(kernel_filename_eval, \"rb\") as f:\n",
    "        K_ev = np.load(f)\n",
    "        \n",
    "    def precomputed_kernel(X1, X2, **args):\n",
    "        K = np.zeros((len(X1), len(X2)))\n",
    "        \n",
    "        idx1 = []\n",
    "        for x in X1: # Needed to get elements in the right order\n",
    "            idx1.append(df_train[df_train['seq'] == x]['Id'].iloc[0])\n",
    "\n",
    "        if sum(df_train['seq'].isin(X2)) >= len(X2): # Check if all elements are in the training set\n",
    "            idx2 = []\n",
    "            for x in X2: # Needed to get elements in the right order\n",
    "                idx2.append(df_train[df_train['seq'] == x]['Id'].iloc[0])\n",
    "            # Extract submatrix using correct indices\n",
    "            K = K_tr[np.ix_(idx1, idx2)]\n",
    "                                        \n",
    "        elif sum(df_eval['seq'].isin(X2)) >= len(X2): # Check if all elements are in the evaluation set\n",
    "            idx2 = []\n",
    "            for x in X2: # Needed to get elements in the right order\n",
    "                idx2.append(df_eval[df_eval['seq'] == x]['Id'].iloc[0])\n",
    "            # Extract submatrix using correct indices\n",
    "            K = K_ev[np.ix_(idx1, idx2)]\n",
    "        \n",
    "        # This is to have a positive matrix 'à la bled'\n",
    "        K += 1e-8\n",
    "        # Divide all elements by row and column values\n",
    "        if normalize:\n",
    "            diag = np.copy(np.diag(K))\n",
    "            K = K / diag[:, None]\n",
    "            K = K / diag\n",
    "        return K\n",
    "    \n",
    "\n",
    "    return precomputed_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00025907, 0.00018632],\n",
       "       [0.00018632, 0.00029442]])"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precomputed_kernel = load_precomputed_kernel(df, df_eval, \n",
    "                                             f\"{data_folder}/Ktrtr{name}_k=4_lambda=0.7.npy\",\n",
    "                                             f\"{data_folder}/Ktreval{name}_k=4_lambda=0.7.npy\",\n",
    "                                             normalize=True)\n",
    "\n",
    "X1 = np.array(['TCCTGTGCACATCTGCACCCCTGTTGTGGCCACAAAATGATCCGGCACCACCCAGTGGGAGACGACAGAGGTGGCAATGGGGTGTCGGCTCTGACGCCTCC',\n",
    "               'TGAAATCCTGCCTCTTCCATGAAGCCGCCTCTGAGAACTGCTGCCAATAGGTGGCTCTTCTTTCTCAGAAGTTCTATTGCATGAATTATTTTCAGTATAAC'])\n",
    "X2 = np.array(['CATCCTACATGATGCCATTGGCATCAGCACCCTAAATCAAATCAAACCAGATGGCTTCACATCCAGCCTCAAAAACTTCCTGTGGAATCACAAGACGTGAA',\n",
    "               'TGAAATCCTGCCTCTTCCATGAAGCCGCCTCTGAGAACTGCTGCCAATAGGTGGCTCTTCTTTCTCAGAAGTTCTATTGCATGAATTATTTTCAGTATAAC'])\n",
    "precomputed_kernel(X2, X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001639476487958876"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2442.6139 / (3859.889 ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Mismatch kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, parent, letter, m=1):\n",
    "        self.m = m\n",
    "        self.parent = parent\n",
    "        self.letter = letter\n",
    "        self.sequence = self.parent.get_sequence()+self.letter\n",
    "        self.pointers = []\n",
    "        self.mismatch_per_pointer = []\n",
    "        \n",
    "    def get_sequence():\n",
    "        return self.sequence\n",
    "    \n",
    "    def get_pointers():\n",
    "        return self.pointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree(Node):\n",
    "    def __init__(self,k,m):\n",
    "        self.root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBFBUDeE0a0R"
   },
   "source": [
    "## B) Algorithms\n",
    "### 1. Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "1Mg97hlq0a0R"
   },
   "outputs": [],
   "source": [
    "def compute_KRR_MLE(X, y, lamb, sig=10):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    - X (size: N_trxd): the points of the training set\n",
    "    - y (size: N_trx1): the values of the classes\n",
    "    outputs:\n",
    "    - the value of MLE estimation (w_hat, b_hat) in the kernel ridge regression model\n",
    "    \"\"\"\n",
    "    K = Gaussian_kernel(X, X, sig=sig)\n",
    "    alpha = np.linalg.inv(K+lamb*X.shape[1]*np.eye(X.shape[1]))@y.T\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "G8xihAC20a0R"
   },
   "outputs": [],
   "source": [
    "def predict_KRR(X_tr, X_te, alpha, sig=10):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    - X_tr (size N_trxd): the points of the training set\n",
    "    - X_te (size N_texd): the points of the test set we want to classify\n",
    "    - w (size: 1xd): the weights of the affine mapping \n",
    "    - b (size: 1x1): the constant of the affine mapping\n",
    "    output:\n",
    "     - the predicted class for the associated y_te given the\n",
    "    Linear Regression parameters\n",
    "    \"\"\"    \n",
    "    K_te_tr = Gaussian_kernel(X_tr, X_te, sig=sig)\n",
    "    return 2*(alpha.T@K_te_tr>0).astype(\"int\")-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "AHIjYIWA0a0S"
   },
   "outputs": [],
   "source": [
    "class KernelRidgeRegressor(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, lamb=1., sigma=1., kernel='gaussian'):\n",
    "        \"\"\"\n",
    "        This class implements methods for fitting and predicting with a KernelRidgeRegressor used for classification \n",
    "        (by thresholding the value regressed). Any kernel can be used. \n",
    "        inputs:\n",
    "        - lamb : the regularisation parameter \n",
    "        - sigma : the parameter of the Gaussian kernel (if Gaussian kernel selected)\n",
    "        - kernel : the kernel we consider\n",
    "        \"\"\"\n",
    "        self.lamb = lamb\n",
    "        self.sigma = sigma\n",
    "        self.kernel = kernel\n",
    "        if self.kernel == 'gaussian':\n",
    "            self.kernel_ = partial(Gaussian_kernel, sig=sigma)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Kernel {self.kernel} is not implemented yet\")\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "        - X (size: N_trxd): the points of the training set\n",
    "        - y (size: N_trx1): the values of the classes\n",
    "        \"\"\"\n",
    "        # We keep values of training in memory for prediction\n",
    "        self.X_tr_ = np.copy(X)\n",
    "        K = self.kernel_(X, X, sig=self.sigma)\n",
    "        self.alpha_ = np.linalg.inv(K+self.lamb*X.shape[0]*np.eye(X.shape[0]))@y\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "        - X (size N_texd): the points in R^d we want to classify\n",
    "        output:\n",
    "         - the predicted class for the associated y given the\n",
    "        Linear Regression parameters\n",
    "        \"\"\"\n",
    "        K_tr_te = self.kernel_(self.X_tr_, X, sig=self.sigma)\n",
    "        \n",
    "        return 2 * (self.alpha_.T@K_tr_te > 0).reshape(-1, ).astype(\"int\") - 1\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "        - X (size N_texd): the points in R^d we want to classify\n",
    "        - y (size N_tex1): the labels of the points\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        \n",
    "        return np.sum(y_pred == y)/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kgsnnyjd0a0S",
    "outputId": "a442b499-687a-45c1-e093-5c024d87d119",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'gaussian', 'lamb': 0.1, 'sigma': 0.5789473684210527}\n",
      "Accuracy on train set 0: 1.00\n",
      "Accuracy on test set 0 : 0.57\n",
      "{'kernel': 'gaussian', 'lamb': 0.1, 'sigma': 0.6578947368421053}\n",
      "Accuracy on train set 1: 1.00\n",
      "Accuracy on test set 1 : 0.59\n",
      "{'kernel': 'gaussian', 'lamb': 0.1, 'sigma': 0.5}\n",
      "Accuracy on train set 2: 1.00\n",
      "Accuracy on test set 2 : 0.67\n"
     ]
    }
   ],
   "source": [
    "dim = 100\n",
    "Nb_samples = 2000\n",
    "prop_test = 0.2\n",
    "lamb = 0.5\n",
    "sigma = 1.2\n",
    "\n",
    "all_y_eval = []\n",
    "\n",
    "np.random.seed(1)\n",
    "for name in [0, 1, 2]:\n",
    "    # Data Processing\n",
    "    X = pd.read_csv(f'{data_folder}/Xtr{name}_mat100.csv', sep = ' ', index_col=False, header=None).to_numpy()\n",
    "    y = pd.read_csv(f'{data_folder}/Ytr{name}.csv')\n",
    "    y = y[\"Bound\"].to_numpy()\n",
    "    y[y==0] = -1\n",
    "    \n",
    "    mean, std = X.mean(axis=0), X.std(axis=0)\n",
    "    X = (X - mean)/std\n",
    "\n",
    "    tr_indices = np.random.choice(Nb_samples, size=int((1-prop_test)*Nb_samples), replace=False)\n",
    "    te_indices = [idx for idx in range(Nb_samples) if idx not in tr_indices]\n",
    "\n",
    "    X_tr = X[tr_indices]\n",
    "    X_te = X[te_indices]\n",
    "    \n",
    "    y_tr = y[tr_indices]\n",
    "    y_te = y[te_indices]\n",
    "    \n",
    "    assert X_tr.shape[0] + X_te.shape[0] == X.shape[0]\n",
    "    assert y_tr.shape[0] + y_te.shape[0] == y.shape[0]\n",
    "    \n",
    "    # Fitting\n",
    "    params = {'lamb': np.linspace(0.1, 2, 2), 'sigma': np.linspace(0.5, 2, 20), 'kernel': ['gaussian']}\n",
    "    krr = GridSearchCV(KernelRidgeRegressor(), params)\n",
    "#     krr = KernelRidgeRegressor()\n",
    "    \n",
    "    krr.fit(X_tr,y_tr)\n",
    "    \n",
    "    print(krr.best_params_)\n",
    "    \n",
    "    print(f\"Accuracy on train set {name}: {krr.score(X_tr, y_tr):.2f}\")\n",
    "    print(f\"Accuracy on test set {name} : {krr.score(X_te, y_te):.2f}\")\n",
    "    \n",
    "    # Prediction on the new set\n",
    "    X_eval = pd.read_csv(f'{data_folder}/Xte{name}_mat100.csv', sep = ' ', index_col=False, header=None).to_numpy()\n",
    "    X_eval = (X_eval - mean)/std\n",
    "    y_eval = krr.predict(X_eval)\n",
    "    all_y_eval.append(y_eval)\n",
    "    \n",
    "all_y_eval = np.hstack(all_y_eval).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9m6sPN00a0S"
   },
   "source": [
    "### 2. Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "id": "dhSUDIUp0a0S"
   },
   "outputs": [],
   "source": [
    "class KernelSVM(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, lamb=1., sigma=1., k=3, precomputed_kernel=None, normalize=False, kernel='gaussian'):\n",
    "        \"\"\"\n",
    "        This class implements methods for fitting and predicting with a KernelRidgeRegressor used for classification \n",
    "        (by thresholding the value regressed). Any kernel can be used. \n",
    "        inputs:\n",
    "        - lamb : the regularisation parameter \n",
    "        - sigma : the parameter of the Gaussian kernel (if Gaussian kernel selected)\n",
    "        - kernel : the kernel we consider\n",
    "        \"\"\"\n",
    "        self.lamb = lamb\n",
    "        self.sigma = sigma\n",
    "        self.k = k\n",
    "        self.normalize = normalize\n",
    "        self.kernel = kernel\n",
    "        if self.kernel == 'gaussian':\n",
    "            self.kernel_ = partial(Gaussian_kernel, sig=sigma)\n",
    "        elif self.kernel == 'spectrum':\n",
    "            self.kernel_ = partial(Spectrum_kernel, k=k)\n",
    "        elif self.kernel == 'substring':\n",
    "            if precomputed_kernel is not None:\n",
    "                self.kernel_ = precomputed_kernel\n",
    "            else:\n",
    "                warnings.warn(\"Computing the kernel on the fly is computationnally heavy, you should probably precompute it.\")\n",
    "                self.kernel_ = partial(substring_kernel, k=k)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Kernel {self.kernel} is not implemented yet\")\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "        - X (size: N_trxd): the points of the training set\n",
    "        - y (size: N_trx1): the values of the classes\n",
    "        \"\"\"\n",
    "        # We keep values of training in memory for prediction\n",
    "        N_tr = X.shape[0]\n",
    "        self.X_tr_ = np.copy(X)\n",
    "\n",
    "        if self.kernel == 'gaussian':\n",
    "            K = self.kernel_(X, X, sig=self.sigma)\n",
    "        elif self.kernel == 'spectrum':\n",
    "            K = self.kernel_(X, X, k=self.k[0])\n",
    "            for i in range(len(self.k)-1):\n",
    "                K+=self.kernel_(X, X, k=self.k[i+1])\n",
    "        elif self.kernel == 'substring':\n",
    "            K = self.kernel_(X, X)\n",
    "            \n",
    "        if self.normalize:\n",
    "            self.tr_diag_ = np.copy(np.diag(K))\n",
    "            K /= self.tr_diag_[:, None]\n",
    "            K /= self.tr_diag_\n",
    "            \n",
    "        # Define QP and solve it with cvxpy\n",
    "        alpha = cp.Variable(N_tr)\n",
    "        objective = cp.Maximize(2*alpha.T@y - cp.quad_form(alpha, K))\n",
    "        constraints = [0 <= cp.multiply(y,alpha), cp.multiply(y,alpha) <= 1/(2*self.lamb*N_tr)]\n",
    "        prob = cp.Problem(objective, constraints)\n",
    "\n",
    "        # The optimal objective value is returned by `prob.solve()`.\n",
    "        result = prob.solve()\n",
    "        # The optimal value for x is stored in `x.value`.\n",
    "        self.alpha_ = alpha.value\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "        - X (size N_texd): the points in R^d we want to classify\n",
    "        output:\n",
    "         - the predicted class for the associated y given the\n",
    "        Linear Regression parameters\n",
    "        \"\"\"\n",
    "        if self.kernel == 'gaussian':\n",
    "            K_tr_te = self.kernel_(self.X_tr_, X, sig=self.sigma)\n",
    "        elif self.kernel == 'spectrum':\n",
    "            K_tr_te = self.kernel_(self.X_tr_, X, k=self.k[0])\n",
    "            for i in range(len(self.k)-1):\n",
    "                K_tr_te+=self.kernel_(self.X_tr_, X, k=self.k[i+1])\n",
    "        elif self.kernel == 'substring':\n",
    "            K_tr_te = self.kernel_(self.X_tr_, X)\n",
    "            \n",
    "        if self.normalize:\n",
    "            K_tr_te /= np.power(self.tr_diag_[:, None], 2)\n",
    "        \n",
    "        return 2 * (self.alpha_.T@K_tr_te > 0).reshape(-1, ).astype(\"int\") - 1\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "        - X (size N_texd): the points in R^d we want to classify\n",
    "        - y (size N_tex1): the labels of the points\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        \n",
    "        return np.sum(y_pred == y)/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7258116 , 0.0103188 , 0.79308337, 0.04436423])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar = np.random.rand(4, 4)\n",
    "diag = np.copy(np.diag(ar))\n",
    "ar /= diag **2\n",
    "diag ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTsajMKQSp2_"
   },
   "source": [
    "#### Gaussian Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "YNl7NJXm0a0S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'gaussian', 'lamb': 1e-07, 'sigma': 100.0}\n",
      "Accuracy on train set 0: 0.99\n",
      "Accuracy on test set 0 : 0.62\n",
      "{'kernel': 'gaussian', 'lamb': 1e-10, 'sigma': 1.0}\n",
      "Accuracy on train set 1: 1.00\n",
      "Accuracy on test set 1 : 0.60\n",
      "{'kernel': 'gaussian', 'lamb': 1e-07, 'sigma': 100.0}\n",
      "Accuracy on train set 2: 0.99\n",
      "Accuracy on test set 2 : 0.72\n"
     ]
    }
   ],
   "source": [
    "dim = 100\n",
    "Nb_samples = 2000\n",
    "prop_test = 0.2\n",
    "lamb = 0.5\n",
    "sigma = 1.2\n",
    "\n",
    "all_y_eval = []\n",
    "\n",
    "np.random.seed(1)\n",
    "for name in [0, 1, 2]:\n",
    "    # Data Processing\n",
    "    X = pd.read_csv(f'{data_folder}/Xtr{name}_mat100.csv', sep = ' ', index_col=False, header=None).to_numpy()\n",
    "    y = pd.read_csv(f'{data_folder}/Ytr{name}.csv')\n",
    "    y = y[\"Bound\"].to_numpy()\n",
    "    y[y==0] = -1\n",
    "    \n",
    "    mean, std = X.mean(axis=0), X.std(axis=0)\n",
    "    X = (X - mean)/std\n",
    "\n",
    "    tr_indices = np.random.choice(Nb_samples, size=int((1-prop_test)*Nb_samples), replace=False)\n",
    "    te_indices = [idx for idx in range(Nb_samples) if idx not in tr_indices]\n",
    "\n",
    "    X_tr = X[tr_indices]\n",
    "    X_te = X[te_indices]\n",
    "    \n",
    "    y_tr = y[tr_indices]\n",
    "    y_te = y[te_indices]\n",
    "    \n",
    "    assert X_tr.shape[0] + X_te.shape[0] == X.shape[0]\n",
    "    assert y_tr.shape[0] + y_te.shape[0] == y.shape[0]\n",
    "    \n",
    "    # Fitting\n",
    "    params = {'lamb': np.logspace(-10., -7., 4), 'sigma': np.logspace(-1., 2., 4), 'kernel': ['gaussian']}\n",
    "    ksvm = GridSearchCV(KernelSVM(), params)\n",
    "#     krr = KernelRidgeRegressor()\n",
    "    \n",
    "    ksvm.fit(X_tr,y_tr)\n",
    "    \n",
    "    print(ksvm.best_params_)\n",
    "    \n",
    "    print(f\"Accuracy on train set {name}: {ksvm.score(X_tr, y_tr):.2f}\")\n",
    "    print(f\"Accuracy on test set {name} : {ksvm.score(X_te, y_te):.2f}\")\n",
    "    \n",
    "    # Prediction on the new set\n",
    "    X_eval = pd.read_csv(f'{data_folder}/Xte{name}_mat100.csv', sep = ' ', index_col=False, header=None).to_numpy()\n",
    "    X_eval = (X_eval - mean)/std\n",
    "    y_eval = ksvm.predict(X_eval)\n",
    "    all_y_eval.append(y_eval)\n",
    "    \n",
    "all_y_eval = np.hstack(all_y_eval).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gPd2jimSvGR"
   },
   "source": [
    "#### Spectrum Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "hjpfylDEImWk",
    "outputId": "15104b61-5bd3-443c-e2cf-45382846a0ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set 0: 0.72\n"
     ]
    }
   ],
   "source": [
    "## Kernel SVM with Spectrum kernel\n",
    "\n",
    "dim = 100\n",
    "Nb_samples = 2000\n",
    "prop_test = 0.2\n",
    "lamb = 0.5\n",
    "sigma = 1.2\n",
    "k = [4,5,6]\n",
    "\n",
    "all_y_eval = []\n",
    "\n",
    "np.random.seed(1)\n",
    "for name in [0, 1, 2]:\n",
    "    # Data Processing\n",
    "    df = pd.read_csv(f'{data_folder}/Xtr{name}.csv')\n",
    "    X = np.array(df['seq'])\n",
    "    y = pd.read_csv(f'{data_folder}/Ytr{name}.csv')\n",
    "    y = y[\"Bound\"].to_numpy()\n",
    "    y[y==0] = -1\n",
    "    \n",
    "\n",
    "    tr_indices = np.random.choice(Nb_samples, size=int((1-prop_test)*Nb_samples), replace=False)\n",
    "    te_indices = [idx for idx in range(Nb_samples) if idx not in tr_indices]\n",
    "\n",
    "    X_tr = X[tr_indices]\n",
    "    X_te = X[te_indices]\n",
    "    \n",
    "    y_tr = y[tr_indices]\n",
    "    y_te = y[te_indices]\n",
    "    \n",
    "    assert X_tr.shape[0] + X_te.shape[0] == X.shape[0]\n",
    "    assert y_tr.shape[0] + y_te.shape[0] == y.shape[0]\n",
    "    \n",
    "    # Fitting\n",
    "    # params = {'lamb': np.logspace(-10., -7., 4), 'k': np.array([3,4,5,6]), 'kernel': ['spectrum']}\n",
    "    # ksvm = GridSearchCV(KernelSVM(), params)\n",
    "#     krr = KernelRidgeRegressor()\n",
    "    ksvm = KernelSVM(lamb = lamb, k=k, kernel='spectrum')\n",
    "    \n",
    "    ksvm.fit(X_tr,y_tr)\n",
    "    \n",
    "    #print(ksvm.best_params_)\n",
    "    \n",
    "    print(f\"Accuracy on train set {name}: {ksvm.score(X_tr, y_tr):.2f}\")\n",
    "    print(f\"Accuracy on test set {name} : {ksvm.score(X_te, y_te):.2f}\")\n",
    "    \n",
    "    # Prediction on the new set\n",
    "    X_eval = np.array(pd.read_csv(f'{data_folder}/Xte{name}.csv')['seq'])\n",
    "    y_eval = ksvm.predict(X_eval)\n",
    "    all_y_eval.append(y_eval)\n",
    "    \n",
    "all_y_eval = np.hstack(all_y_eval).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substring Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set 0: 0.72\n",
      "Accuracy on test set 0 : 0.64\n"
     ]
    }
   ],
   "source": [
    "# Kernel SVM with substring kernel\n",
    "\n",
    "dim = 100\n",
    "Nb_samples = 2000\n",
    "prop_test = 0.2\n",
    "lamb = 1e-6\n",
    "\n",
    "all_y_eval = []\n",
    "\n",
    "np.random.seed(1)\n",
    "name = 0\n",
    "# Data Processing\n",
    "df = pd.read_csv(f'{data_folder}/Xtr{name}.csv')\n",
    "X = np.array(df['seq'])\n",
    "y = pd.read_csv(f'{data_folder}/Ytr{name}.csv')\n",
    "y = y[\"Bound\"].to_numpy()\n",
    "y[y==0] = -1\n",
    "\n",
    "df_eval = pd.read_csv(f'{data_folder}/Xte{name}.csv')\n",
    "X_eval = np.array(df_eval['seq'])\n",
    "\n",
    "precomputed_kernel = load_precomputed_kernel(df, df_eval, \n",
    "                                             f\"{data_folder}/Ktrtr{name}_k=4_lambda=0.7.npy\",\n",
    "                                             f\"{data_folder}/Ktreval{name}_k=4_lambda=0.7.npy\")\n",
    "\n",
    "tr_indices = np.random.choice(Nb_samples, size=int((1-prop_test)*Nb_samples), replace=False)\n",
    "te_indices = [idx for idx in range(Nb_samples) if idx not in tr_indices]\n",
    "\n",
    "X_tr = X[tr_indices]\n",
    "X_te = X[te_indices]\n",
    "\n",
    "y_tr = y[tr_indices]\n",
    "y_te = y[te_indices]\n",
    "\n",
    "assert X_tr.shape[0] + X_te.shape[0] == X.shape[0]\n",
    "assert y_tr.shape[0] + y_te.shape[0] == y.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "# Fitting\n",
    "# params = {'lamb': np.logspace(-10., -7., 4), 'k': np.array([3,4,5,6]), 'kernel': ['spectrum']}\n",
    "# ksvm = GridSearchCV(KernelSVM(), params)\n",
    "ksvm = KernelSVM(lamb=lamb, precomputed_kernel=precomputed_kernel, normalize=False, kernel='substring')\n",
    "\n",
    "ksvm.fit(X_tr,y_tr)\n",
    "\n",
    "# print(ksvm.best_params_)\n",
    "\n",
    "print(f\"Accuracy on train set {name}: {ksvm.score(X_tr, y_tr):.2f}\")\n",
    "print(f\"Accuracy on test set {name} : {ksvm.score(X_te, y_te):.2f}\")\n",
    "\n",
    "# Prediction on the new set\n",
    "y_eval = ksvm.predict(X_eval)\n",
    "all_y_eval.append(y_eval)\n",
    "\n",
    "all_y_eval = np.hstack(all_y_eval).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "id": "aARgH1w10a0T"
   },
   "outputs": [],
   "source": [
    "ids = np.arange(all_y_eval.shape[0])\n",
    "filename = \"results/submission_substring0_svm.csv\"\n",
    "\n",
    "# write_csv(ids, all_y_eval, filename)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "KM_challenge.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
